import os
import torch
import asyncio
from transformers import pipeline, AutoTokenizer, AutoModelForCausalLM, AutoModelForSequenceClassification
from typing import Dict, Any, List
from .base_agent import BaseAgent, Message
from infrastructure.database.sqlite.service import DatabaseService
from infrastructure.config.settings import HUGGINGFACE_CONFIG
from infrastructure.config.ai_agents import get_ai_agent_config
from infrastructure.config.prompts import get_prompt
from infrastructure.reports import report_manager
from utils import log, LogLevel

class AIDrivenCodeQualityAgent(BaseAgent):
    """AI-driven code quality analysis agent - utilizing AI model capabilities"""
    
    def __init__(self):
        super().__init__("ai_code_quality_agent", "AI Code Quality Agent")  # rename for legacy test expectation
        self.used_device = "gpu"
        self.used_device_map = None  # æ·»åŠ è®¾å¤‡æ˜ å°„å‚æ•°
        self.db_service = DatabaseService()
        # ä»ç»Ÿä¸€é…ç½®è·å–
        self.agent_config = get_ai_agent_config().get_code_quality_agent_config()
        self.model_config = HUGGINGFACE_CONFIG["models"]["code_quality"]
        
        # AIæ¨¡å‹ç»„ä»¶
        self.code_understanding_model = None
        self.text_generation_model = None
        self.classification_model = None

    async def _initialize_models(self):
        """Initialize AI model - supports both CPU and GPU based on used_device"""
        try:
            # éªŒè¯ used_device å‚æ•°
            if self.used_device not in ["cpu", "gpu"]:
                log("ai_code_quality_agent", LogLevel.WARNING, f"âš ï¸ æ— æ•ˆçš„è®¾å¤‡å‚æ•°: {self.used_device}ï¼Œå›é€€åˆ°CPU")
                self.used_device = "cpu"
            
            # ä¼˜å…ˆä½¿ç”¨agentä¸“å±é…ç½®ï¼Œå›é€€åˆ°HUGGINGFACE_CONFIG
            model_name = self.agent_config.get("model_name", self.model_config["name"])
            cache_dir = get_ai_agent_config().get_model_cache_dir()
            # ç¡®ä¿ç¼“å­˜ç›®å½•æ˜¯ç»å¯¹è·¯å¾„ï¼ˆä¸user_comm_agentä¿æŒä¸€è‡´ï¼‰
            if not os.path.isabs(cache_dir):
                cache_dir = os.path.abspath(cache_dir)
            log("ai_code_quality_agent", LogLevel.INFO, f"ğŸ’¾ ç¼“å­˜ç›®å½•: {cache_dir}")

            device = -1 if self.used_device == "cpu" else 0
            device_mode = "CPU" if self.used_device == "cpu" else "GPU"
            
            # ä»…åœ¨CPUæ¨¡å¼ä¸‹è®¾ç½®çº¿ç¨‹æ•°
            if self.used_device == "cpu":
                cpu_threads = self.agent_config.get("cpu_threads", 4)
                torch.set_num_threads(cpu_threads)
            
            log("ai_code_quality_agent", LogLevel.INFO, f"ğŸ¤– [ai_code_quality_agent] æ­£åœ¨åŠ è½½ä»£ç ç†è§£æ¨¡å‹ ({device_mode}æ¨¡å¼): {model_name}")
            try:
                # ç¡®ä¿ç¼“å­˜ç›®å½•å­˜åœ¨
                os.makedirs(cache_dir, exist_ok=True)

                local_files_only = False
                # æ£€æŸ¥æ¨¡å‹æ–‡ä»¶æ˜¯å¦å·²å­˜åœ¨
                model_path = os.path.join(cache_dir, f"models--{model_name.replace('/', '--')}")
                # æ£€æŸ¥å¿«ç…§ç›®å½•æ˜¯å¦å­˜åœ¨ä¸”ä¸ä¸ºç©º
                snapshots_path = os.path.join(model_path, "snapshots")
                model_files_exist = (
                    os.path.exists(model_path) and 
                    os.path.exists(snapshots_path) and 
                    os.listdir(snapshots_path)
                )

                if model_files_exist:
                    local_files_only = True
                    log("ai_code_quality_agent", LogLevel.INFO, "ğŸ” æ£€æµ‹åˆ°æœ¬åœ°ç¼“å­˜æ¨¡å‹æ–‡ä»¶ï¼Œå°†ä½¿ç”¨æœ¬åœ°æ–‡ä»¶åŠ è½½")
                else:
                    log("ai_code_quality_agent", LogLevel.INFO, "ğŸŒ æœªæ£€æµ‹åˆ°æœ¬åœ°ç¼“å­˜æ¨¡å‹ï¼Œå°†ä»ç½‘ç»œä¸‹è½½")
                
                log("ai_code_quality_agent", LogLevel.INFO, "ğŸ”§ ä½¿ç”¨microsoft codebert-baseé…ç½®åŠ è½½tokenizer...")
                if local_files_only and model_files_exist:
                    snapshot_dirs = os.listdir(snapshots_path)
                    if snapshot_dirs:
                        model_local_path = os.path.join(snapshots_path, snapshot_dirs[0])
                        self.tokenizer = AutoTokenizer.from_pretrained(
                            model_local_path,
                            cache_dir=cache_dir,
                            trust_remote_code=True,
                            local_files_only=True
                        )
                    else:
                        raise Exception("[ai_code_quality_agent] æœªæ‰¾åˆ°æœ‰æ•ˆçš„æ¨¡å‹å¿«ç…§ç›®å½•")
                else:
                    self.tokenizer = AutoTokenizer.from_pretrained(
                        model_name, 
                        cache_dir=cache_dir,
                        trust_remote_code=True,
                        local_files_only=local_files_only
                    )
                log("ai_code_quality_agent", LogLevel.INFO, "âœ… TokenizeråŠ è½½æˆåŠŸ")

                # é…ç½®tokenizer
                if self.tokenizer.pad_token is None:
                    self.tokenizer.pad_token = self.tokenizer.eos_token
                log("ai_code_quality_agent", LogLevel.INFO, "ğŸ”§ å·²è®¾ç½®pad_token")

                log("ai_code_quality_agent", LogLevel.INFO, "ğŸ”§ æ­£åœ¨åˆ›å»ºå¯¹è¯ç”Ÿæˆpipeline...")
                model_kwargs = {
                    "torch_dtype": getattr(torch, self.agent_config.get("torch_dtype", "float32")),
                    "low_cpu_mem_usage": self.agent_config.get("low_cpu_mem_usage", True),
                    "cache_dir": cache_dir,
                }
                if local_files_only:
                    model_kwargs["local_files_only"] = True

                if local_files_only and model_files_exist:
                    # ç›´æ¥ä½¿ç”¨æœ¬åœ°æ¨¡å‹è·¯å¾„è€Œä¸æ˜¯æ¨¡å‹æ ‡è¯†ç¬¦
                    snapshot_dirs = os.listdir(snapshots_path)
                    if snapshot_dirs:
                        model_local_path = os.path.join(snapshots_path, snapshot_dirs[0])
                        self.conversation_model = pipeline(
                            "text-classification",
                            model=model_local_path,
                            tokenizer=self.tokenizer,
                            device=self.used_device,
                            trust_remote_code=True,
                            model_kwargs=model_kwargs
                        )
                    else:
                        raise Exception("æœªæ‰¾åˆ°æœ‰æ•ˆçš„æ¨¡å‹å¿«ç…§ç›®å½•")
                else:
                    # åœ¨çº¿æ¨¡å¼æˆ–æœ¬åœ°æ–‡ä»¶ä¸å®Œæ•´æ—¶ä½¿ç”¨æ¨¡å‹åç§°
                    self.conversation_model = pipeline(
                        "text-generation",
                        model=model_name,
                        tokenizer=self.tokenizer,
                        device=self.used_device,
                        trust_remote_code=True,
                        model_kwargs=model_kwargs
                    )
                log("ai_code_quality_agent", LogLevel.INFO, "âœ… Pipelineåˆ›å»ºæˆåŠŸ")
            except Exception as model_error:
                log("ai_code_quality_agent", LogLevel.WARNING, f"âš ï¸ [ai_code_quality_agent] ä¸»æ¨¡å‹åŠ è½½å¤±è´¥,å°è¯•å¤‡ç”¨æ¨¡å‹: {model_error}")
                
                if not os.path.exists(cache_dir):
                    log("ai_code_quality_agent", LogLevel.WARNING, f"âŒ ç¼“å­˜ç›®å½•ä¸å­˜åœ¨: {cache_dir}")

                fallback_model = self.agent_config.get("fallback_model", "distilbert-base-uncased")
                self.tokenizer = AutoTokenizer.from_pretrained(
                    fallback_model,
                    cache_dir=cache_dir
                )
                if self.tokenizer.pad_token is None:
                    self.tokenizer.pad_token = self.tokenizer.eos_token
                self.classification_model = pipeline(
                    "text-classification",
                    model=fallback_model,
                    device=device
                )
                log("ai_code_quality_agent", LogLevel.INFO, f"âœ… [ai_code_quality_agent] å¤‡ç”¨æ¨¡å‹åŠ è½½æˆåŠŸ: {fallback_model}")

            try:
                # ä¸º text-generation ä¹Ÿä¼˜å…ˆä½¿ç”¨æœ¬åœ°ç¼“å­˜ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
                tg_model_name = self.agent_config.get("text_generator_model", "gpt2")
                tg_local_files_only = False
                tg_model_path = os.path.join(cache_dir, f"models--{tg_model_name.replace('/', '--')}")
                tg_snapshots_path = os.path.join(tg_model_path, "snapshots")
                tg_model_files_exist = os.path.exists(tg_model_path) and os.path.exists(tg_snapshots_path) and bool(os.listdir(tg_snapshots_path))
                if tg_model_files_exist:
                    tg_local_files_only = True
                    log("ai_code_quality_agent", LogLevel.INFO, "ğŸ” æ£€æµ‹åˆ°æœ¬åœ°ç¼“å­˜æ¨¡å‹æ–‡ä»¶ï¼Œå°†ä½¿ç”¨æœ¬åœ°æ–‡ä»¶åŠ è½½")
                else:
                    log("ai_code_quality_agent", LogLevel.INFO, "ğŸŒ æœªæ£€æµ‹åˆ°æœ¬åœ°ç¼“å­˜æ¨¡å‹ï¼Œå°†ä»ç½‘ç»œä¸‹è½½")
                
                tg_model_kwargs = {"low_cpu_mem_usage": True, "cache_dir": cache_dir}
                if tg_model_files_exist:
                    tg_model_kwargs["local_files_only"] = True

                log("ai_code_quality_agent", LogLevel.INFO, f"ğŸ¤– [ai_code_quality_agent] æ­£åœ¨åŠ è½½æ–‡æœ¬ç”Ÿæˆæ¨¡å‹ ({'æœ¬åœ°' if tg_model_files_exist else 'ç½‘ç»œ'}) : {tg_model_name}")
                if tg_local_files_only and tg_model_files_exist:
                    tg_snapshot_dirs = os.listdir(tg_snapshots_path)
                    tg_model_local_path = os.path.join(tg_snapshots_path, tg_snapshot_dirs[0])
                    self.text_generation_model = pipeline(
                        "text-generation",
                        model=tg_model_local_path,
                        device=device,
                        model_kwargs=tg_model_kwargs
                    )
                else:
                    log("ai_code_quality_agent", LogLevel.INFO, f"ğŸ¤– [ai_code_quality_agent] æ­£åœ¨åŠ è½½æ–‡æœ¬ç”Ÿæˆæ¨¡å‹ (ç½‘ç»œ) : {tg_model_name}")
                    self.text_generation_model = pipeline(
                        "text-generation",
                        model=tg_model_name,
                        device=device,
                        model_kwargs=tg_model_kwargs
                    )
                if self.text_generation_model.tokenizer.pad_token is None:
                    self.text_generation_model.tokenizer.pad_token = self.text_generation_model.tokenizer.eos_token
                log("ai_code_quality_agent", LogLevel.INFO, "âœ… [ai_code_quality_agent] æ–‡æœ¬ç”Ÿæˆæ¨¡å‹åŠ è½½æˆåŠŸ")
            except Exception as gen_error:
                log("ai_code_quality_agent", LogLevel.WARNING, f"âš ï¸ [ai_code_quality_agent] æ–‡æœ¬ç”Ÿæˆæ¨¡å‹åŠ è½½å¤±è´¥,å°†ä½¿ç”¨æ¨¡æ¿ç”Ÿæˆ: {gen_error}")
                self.text_generation_model = None
            self.code_understanding_model = self.classification_model
            log("ai_code_quality_agent", LogLevel.INFO, f"âœ… [ai_code_quality_agent] AIæ¨¡å‹åˆå§‹åŒ–å®Œæˆ ({device_mode}æ¨¡å¼)")

        except Exception as e:
            log("ai_code_quality_agent", LogLevel.ERROR, f"âŒ [ai_code_quality_agent] AIæ¨¡å‹åˆå§‹åŒ–å¤±è´¥: {e}")
            log("ai_code_quality_agent", LogLevel.INFO, "ğŸ”„ [ai_code_quality_agent] åˆ‡æ¢åˆ°æ— AIæ¨¡å¼,ä½¿ç”¨åŸºç¡€åˆ†æ")
            self.code_understanding_model = None
            self.classification_model = None
            self.text_generation_model = None
            
    async def handle_message(self, message: Message):
        """Process code quality analysis request"""
        if message.message_type == "quality_analysis_request":
            requirement_id = message.content.get("requirement_id")
            code_content = message.content.get("code_content", "")
            code_directory = message.content.get("code_directory", "")
            file_path = message.content.get("file_path")
            run_id = message.content.get("run_id")
            if not self.code_understanding_model:
                await self._initialize_models()
            # ä¸å†è¿™é‡Œè§¦å‘é™æ€æ‰«æï¼Œé¿å…ä¸é›†æˆå™¨çš„åˆå§‹æ´¾å‘é€ æˆé‡å¤ (å‡ºç° run_id=None çš„ç¬¬äºŒæ¬¡æ‰«æ)
            # è´¨é‡ä»£ç†åªç­‰å¾… static_scan_complete æ¶ˆæ¯å†åšç»¼åˆåˆ†æ
            return
        elif message.message_type == "static_scan_complete":
            # æ¥æ”¶é™æ€æ‰«æç»“æœå¹¶è¿›è¡ŒAIç»¼åˆåˆ†æ (è¿è¡Œå·²ç»“æŸåä»å¯èƒ½åˆ°è¾¾)
            requirement_id = message.content.get("requirement_id")
            static_scan_results = message.content.get("static_scan_results", {})
            code_content = message.content.get("code_content", "")
            code_directory = message.content.get("code_directory", "")
            file_path = message.content.get("file_path")
            run_id = message.content.get('run_id')
            # æ£€æµ‹è¿è¡Œæ˜¯å¦å·²é—­åˆï¼Œä¸æ‰“å°ä»»ä½•æ­£å¸¸ä¿¡æ¯
            run_closed = False
            if run_id:
                from pathlib import Path as _P
                run_dir = _P(__file__).parent.parent.parent / 'reports' / 'analysis' / run_id
                if (run_dir / 'run_summary.json').exists():
                    run_closed = True
            result = await self._ai_comprehensive_analysis(
                code_content, code_directory, static_scan_results,
                silent=True  # æ€»æ˜¯é™é»˜æ­£å¸¸è¾“å‡º
            )
            if run_id:
                try:
                    agent_payload = {
                        "requirement_id": requirement_id,
                        "file_path": file_path,
                        "run_id": run_id,
                        "code_quality_result": result,
                        "generated_at": self._get_current_time()
                    }
                    report_manager.generate_run_scoped_report(run_id, agent_payload, f"quality_req_{requirement_id}.json", subdir="agents/code_quality")
                except Exception as e:
                    log("ai_code_quality_agent", LogLevel.WARNING, f"âš ï¸ ä»£ç è´¨é‡Agentå•ç‹¬æŠ¥å‘Šç”Ÿæˆå¤±è´¥ requirement={requirement_id} run_id={run_id}: {e}")
            await self.dispatch_message(
                receiver="user_comm_agent",
                content={
                    "requirement_id": requirement_id,
                    "agent_type": "ai_code_quality",
                    "results": result,
                    "analysis_complete": True,
                    "file_path": file_path,
                    "run_id": run_id
                },
                message_type="analysis_result"
            )
            await self.dispatch_message(
                receiver="summary_agent",
                content={
                    "requirement_id": requirement_id,
                    "analysis_type": "ai_analysis",
                    "result": result,
                    "file_path": file_path,
                    "run_id": run_id
                },
                message_type="analysis_result"
            )
            # ç§»é™¤å®Œæˆæç¤ºæ‰“å°

    async def _ai_comprehensive_analysis(self, code_content: str, code_directory: str,
                                        static_scan_results: Dict[str, Any], silent: bool = False) -> Dict[str, Any]:
        """ç»¼åˆä»£ç è´¨é‡åˆ†æï¼šåªåœ¨é”™è¯¯æ—¶æ‰“å°"""
        try:
            ai_analysis = await self._ai_driven_quality_analysis(code_content, code_directory, silent=True)
            static_analysis_insights = await self._analyze_static_scan_results(static_scan_results)
            comprehensive_assessment = await self._ai_comprehensive_assessment(
                ai_analysis, static_scan_results, static_analysis_insights
            )
            integrated_suggestions = await self._generate_integrated_suggestions(
                ai_analysis, static_scan_results, comprehensive_assessment
            )
            final_report = await self._generate_final_quality_report(
                ai_analysis, static_scan_results, comprehensive_assessment, integrated_suggestions
            )
            return {
                "analysis_type": "comprehensive_ai_static_analysis",
                "ai_analysis": ai_analysis,
                "static_scan_results": static_scan_results,
                "static_analysis_insights": static_analysis_insights,
                "comprehensive_assessment": comprehensive_assessment,
                "integrated_suggestions": integrated_suggestions,
                "final_report": final_report,
                "analysis_timestamp": self._get_current_time(),
                "analysis_status": "completed"
            }
        except Exception as e:
            log("ai_code_quality_agent", LogLevel.ERROR, f"âŒ AIç»¼åˆåˆ†æè¿‡ç¨‹ä¸­å‡ºé”™: {e}")
            return {
                "analysis_type": "comprehensive_analysis_error",
                "error_message": str(e),
                "analysis_status": "failed"
            }

    async def _ai_driven_quality_analysis(self, code_content: str, code_directory: str, silent: bool = False) -> Dict[str, Any]:
        """åº•å±‚è´¨é‡åˆ†æï¼šä»…é”™è¯¯æ‰“å°"""
        try:
            all_code_content = await self._read_code_files(code_directory) if code_directory else code_content
            code_embeddings = await self._get_code_embeddings(all_code_content)
            quality_classification = await self._classify_code_quality(all_code_content)
            analysis_report = await self._generate_quality_report(all_code_content)
            improvement_suggestions = await self._generate_improvement_suggestions(all_code_content)
            refactoring_suggestions = await self._generate_refactoring_suggestions(all_code_content)
            return {
                "ai_analysis_type": "comprehensive_quality_analysis",
                "model_used": self.model_config["name"],
                "code_embeddings_summary": code_embeddings,
                "quality_classification": quality_classification,
                "detailed_analysis": analysis_report,
                "improvement_suggestions": improvement_suggestions,
                "refactoring_suggestions": refactoring_suggestions,
                "ai_confidence": 0.85,
                "analysis_timestamp": self._get_current_time(),
                "analysis_status": "completed"
            }
        except Exception as e:
            log("ai_code_quality_agent", LogLevel.ERROR, f"âŒ AIåˆ†æè¿‡ç¨‹ä¸­å‡ºé”™: {e}")
            return {
                "ai_analysis_type": "error",
                "error_message": str(e),
                "analysis_status": "failed"
            }

    async def _get_code_embeddings(self, code_content: str) -> Dict[str, Any]:
        """Use AI model to get code embedding representation - CPU optimized version"""
        try:
            if not self.classification_model:
                return {"error": "AIæ¨¡å‹æœªåŠ è½½", "fallback": True}
            chunks = self._split_code_into_chunks(code_content, max_length=256)
            embeddings_summary = []
            for i, chunk in enumerate(chunks[:3]):
                try:
                    result = self.classification_model(
                        chunk[:200],
                        truncation=True
                    )
                    if result and len(result) > 0:
                        score = result[0].get('score', 0.5)
                        embeddings_summary.append({
                            "chunk_index": i,
                            "semantic_score": float(score),
                            "chunk_length": len(chunk),
                            "model_confidence": float(score)
                        })
                    await asyncio.sleep(0.05)
                except Exception as chunk_error:
                    log("ai_code_quality_agent", LogLevel.WARNING, f"âš ï¸ å¤„ç†å— {i} æ—¶å‡ºé”™: {chunk_error}")
                    continue
            if embeddings_summary:
                avg_score = sum(item["semantic_score"] for item in embeddings_summary) / len(embeddings_summary)
                return {
                    "total_chunks": len(chunks),
                    "processed_chunks": len(embeddings_summary),
                    "embedding_summary": embeddings_summary,
                    "semantic_complexity": avg_score,
                    "processing_mode": "cpu_optimized"
                }
            else:
                return {
                    "error": "æ— æ³•å¤„ç†ä»»ä½•ä»£ç å—",
                    "fallback": True,
                    "processing_mode": "cpu_optimized"
                }
        except Exception as e:
            log("ai_code_quality_agent", LogLevel.WARNING, f"âš ï¸ åµŒå…¥ç”Ÿæˆå¤±è´¥,ä½¿ç”¨ç®€åŒ–åˆ†æ: {e}")
            return {
                "error": f"åµŒå…¥ç”Ÿæˆå¤±è´¥: {e}",
                "fallback_analysis": {
                    "code_length": len(code_content),
                    "estimated_complexity": "medium" if len(code_content) > 1000 else "low"
                },
                "processing_mode": "fallback"
            }

    async def _classify_code_quality(self, code_content: str) -> Dict[str, Any]:
        """Use AI classification model to evaluate code quality"""
        try:
            classification_prompt = f"""
            Analyze the following code for quality assessment:
            Code:
            {code_content[:1000]}
            Quality aspects to evaluate:
            - Readability
            - Maintainability 
            - Performance
            - Security
            """
            if self.classification_model:
                truncated_prompt = classification_prompt[:512]
                result = self.classification_model(
                    truncated_prompt,
                    truncation=True
                )
                return {
                    "predicted_quality": result[0]["label"] if result else "UNKNOWN",
                    "confidence": result[0]["score"] if result else 0.0,
                    "model_prediction": result
                }
            else:
                return {"error": "åˆ†ç±»æ¨¡å‹æœªåˆå§‹åŒ–"}
        except Exception as e:
            return {"error": f"è´¨é‡åˆ†ç±»å¤±è´¥: {e}"}

    def _safe_generate(self, prompt: str, max_new_tokens: int = 128, temperature: float = 0.7) -> str | None:
        """å®‰å…¨å°è£… text-generationï¼ŒåŸºäº token æˆªæ–­é¿å…è¶…é•¿å¯¼è‡´ index out of rangeã€‚
        è¿”å›ç”Ÿæˆæ–‡æœ¬æˆ– None (å¤±è´¥)ã€‚"""
        if not self.text_generation_model:
            return None
        try:
            tokenizer = self.text_generation_model.tokenizer
            model = self.text_generation_model.model
            max_ctx = getattr(model.config, 'n_positions', 1024)
            # ç¼–ç ä¸åŠ ç”Ÿæˆæç¤ºï¼Œé¿å…é‡å¤ç‰¹æ®Štoken
            input_ids = tokenizer(prompt, add_special_tokens=False).input_ids
            reserve = max_new_tokens
            if len(input_ids) + reserve > max_ctx:
                # æˆªæ–­åˆ°å¯ç”¨é•¿åº¦
                keep = max_ctx - reserve
                input_ids = input_ids[:keep]
                prompt = tokenizer.decode(input_ids, skip_special_tokens=True)
            # è°ƒç”¨ pipeline
            out = self.text_generation_model(
                prompt,
                max_new_tokens=max_new_tokens,
                temperature=temperature,
                do_sample=True,
                pad_token_id=tokenizer.eos_token_id
            )
            if out and len(out) > 0:
                return out[0].get('generated_text', '')
            return None
        except Exception as e:
            import traceback
            log("ai_code_quality_agent", LogLevel.ERROR, f"âŒ æ–‡æœ¬ç”Ÿæˆå¤±è´¥: {type(e).__name__}: {e}\n{traceback.format_exc()}")
            return None

    async def _generate_quality_report(self, code_content: str) -> Dict[str, Any]:
        """Use AI to generate detailed quality analysis report (å®‰å…¨ç”Ÿæˆ)"""
        try:
            prompt = get_prompt(
                task_type="code_analysis",
                model_name=self.model_config["name"],
                code_content=code_content[:2000],
                language="python"
            )
            if self.text_generation_model:
                generated_text = self._safe_generate(prompt, max_new_tokens=128, temperature=0.7)
                if generated_text is None or not generated_text.strip():
                    return self._fallback_quality_analysis(code_content) | {"generation_error": "text_generation_failed"}
                analysis_result = self._parse_ai_analysis(generated_text)
                return {
                    "ai_generated_report": generated_text,
                    "structured_analysis": analysis_result,
                    "generation_successful": True
                }
            else:
                return self._fallback_quality_analysis(code_content)
        except Exception as e:
            return {"error": f"æŠ¥å‘Šç”Ÿæˆå¤±è´¥: {e}"}

    async def _generate_improvement_suggestions(self, code_content: str) -> List[Dict[str, Any]]:
        """AI-generated improvement suggestions (å®‰å…¨ç”Ÿæˆ)"""
        try:
            improvement_prompt = f"""
            ä½œä¸ºä»£ç å®¡æŸ¥ä¸“å®¶,ä¸ºä»¥ä¸‹ä»£ç æä¾›å…·ä½“çš„æ”¹è¿›å»ºè®®:
            {code_content[:1500]}
            è¯·æä¾›:
            1. ä¼˜å…ˆçº§é«˜çš„æ”¹è¿›ç‚¹
            2. å…·ä½“çš„ä¿®æ”¹å»ºè®®
            3. æ”¹è¿›åçš„é¢„æœŸæ•ˆæœ
            """
            if self.text_generation_model:
                generated_text = self._safe_generate(improvement_prompt, max_new_tokens=96, temperature=0.65)
                if generated_text is None:
                    return self._fallback_improvement_suggestions(code_content) + [{"error": "suggestion_generation_failed"}]
                suggestions = self._parse_suggestions(generated_text)
                return suggestions if suggestions else self._fallback_improvement_suggestions(code_content)
            else:
                return self._fallback_improvement_suggestions(code_content)
        except Exception as e:
            return [{"error": f"å»ºè®®ç”Ÿæˆå¤±è´¥: {e}"}]

    async def _generate_refactoring_suggestions(self, code_content: str) -> Dict[str, Any]:
        """AI-generated refactoring suggestions (å®‰å…¨ç”Ÿæˆ)"""
        try:
            refactoring_prompt = get_prompt(
                task_type="refactoring",
                model_name=self.model_config["name"],
                code_content=code_content[:1500],
                language="python"
            )
            if self.text_generation_model:
                generated_text = self._safe_generate(refactoring_prompt, max_new_tokens=128, temperature=0.55)
                if generated_text is None:
                    return self._fallback_refactoring_suggestions(code_content) | {"generation_error": "refactoring_generation_failed"}
                return {
                    "ai_refactoring_plan": generated_text,
                    "refactoring_priority": "medium",
                    "estimated_effort": "2-4 hours",
                    "expected_improvements": ["å¯è¯»æ€§æå‡", "ç»´æŠ¤æ€§å¢å¼º", "æ€§èƒ½ä¼˜åŒ–"]
                }
            else:
                return self._fallback_refactoring_suggestions(code_content)
        except Exception as e:
            return {"error": f"é‡æ„å»ºè®®ç”Ÿæˆå¤±è´¥: {e}"}

    async def _analyze_static_scan_results(self, static_scan_results: Dict[str, Any]) -> Dict[str, Any]:
        """ä»é™æ€æ‰«æç»“æœä¸­æç‚¼ç»“æ„åŒ–æ´å¯Ÿã€‚"""
        try:
            if not isinstance(static_scan_results, dict):
                return {"error": "static_scan_results éå­—å…¸", "received_type": str(type(static_scan_results))}
            summary = static_scan_results.get("summary", {}) or {}
            severity = summary.get("severity_breakdown", {}) or {}
            total_issues = summary.get("total_issues", 0)
            grade = summary.get("quality_grade")
            tools = static_scan_results.get("tools_used", [])
            language = static_scan_results.get("language")
            recs = summary.get("recommendations", [])
            insights: List[str] = []
            if total_issues == 0:
                insights.append("æœªå‘ç°é™æ€é—®é¢˜ï¼Œä»£ç åŸºç¡€å¥åº·ã€‚")
            else:
                hi = severity.get("high", 0) + severity.get("critical", 0)
                if hi:
                    insights.append(f"å­˜åœ¨ {hi} ä¸ªé«˜/ä¸¥é‡çº§åˆ«é—®é¢˜ï¼Œéœ€ä¼˜å…ˆå¤„ç†ã€‚")
                md = severity.get("medium", 0)
                if md:
                    insights.append(f"æœ‰ {md} ä¸ªä¸­ç­‰çº§é—®é¢˜ï¼Œå¯æ’æœŸå¤„ç†ã€‚")
                lo = severity.get("low", 0)
                if lo > 15:
                    insights.append("ä½ç­‰çº§æ ·å¼/çº¦å®šé—®é¢˜è¾ƒå¤šï¼Œè€ƒè™‘å¼•å…¥è‡ªåŠ¨æ ¼å¼åŒ–ã€‚")
            if summary.get("has_security_issues"):
                insights.append("æ£€æµ‹åˆ°å®‰å…¨ç›¸å…³é™æ€é—®é¢˜ï¼Œéœ€ç»“åˆå®‰å…¨åˆ†æç»“æœç¡®è®¤é£é™©ã€‚")
            if summary.get("has_type_issues"):
                insights.append("å­˜åœ¨ç±»å‹æ£€æŸ¥é—®é¢˜ï¼Œå»ºè®®è¡¥å…¨ç±»å‹æ³¨è§£ã€‚")
            if grade:
                insights.append(f"é™æ€è´¨é‡ç­‰çº§: {grade}")
            return {
                "static_summary": {
                    "total_issues": total_issues,
                    "severity_breakdown": severity,
                    "quality_grade": grade,
                    "language": language,
                    "tools_used": tools
                },
                "insights": insights,
                "raw_recommendations": recs
            }
        except Exception as e:
            return {"error": f"é™æ€æ‰«æç»“æœåˆ†æå¤±è´¥: {e}"}

    async def _ai_comprehensive_assessment(self, ai_analysis: Dict[str, Any], static_scan_results: Dict[str, Any], static_analysis_insights: Dict[str, Any]) -> Dict[str, Any]:
        """ç»“åˆ AI ä¸é™æ€æ‰«æä¿¡æ¯ç”Ÿæˆç»¼åˆè¯„ä¼°ã€‚"""
        try:
            ai_quality = ai_analysis.get("quality_classification", {})
            static_summary = static_analysis_insights.get("static_summary", {})
            severity = static_summary.get("severity_breakdown", {})
            total = static_summary.get("total_issues", 0)
            grade = static_summary.get("quality_grade")
            risk = "low"
            if severity.get("critical", 0) > 0:
                risk = "critical"
            elif severity.get("high", 0) > 0:
                risk = "high"
            elif severity.get("medium", 0) > 5:
                risk = "medium"
            return {
                "risk_level": risk,
                "estimated_quality_grade": grade or "UNKNOWN",
                "total_issues": total,
                "ai_predicted_quality": ai_quality.get("predicted_quality"),
                "ai_confidence": ai_quality.get("confidence"),
                "key_static_insights": static_analysis_insights.get("insights", [])
            }
        except Exception as e:
            return {"error": f"ç»¼åˆè¯„ä¼°å¤±è´¥: {e}"}

    async def _generate_integrated_suggestions(self, ai_analysis: Dict[str, Any], static_scan_results: Dict[str, Any], comprehensive_assessment: Dict[str, Any]) -> List[Dict[str, Any]]:
        """æ•´åˆå¤šæ¥æºå»ºè®®ã€‚"""
        try:
            suggestions: List[Dict[str, Any]] = []
            for s in ai_analysis.get("improvement_suggestions", [])[:5]:
                if isinstance(s, dict):
                    suggestions.append({
                        "source": "ai_improvement",
                        "description": s.get("description"),
                        "priority": s.get("priority", "medium")
                    })
                elif isinstance(s, str):
                    suggestions.append({"source": "ai_improvement", "description": s, "priority": "medium"})
            for r in static_scan_results.get("summary", {}).get("recommendations", [])[:5]:
                suggestions.append({"source": "static_scan", "description": r, "priority": "medium"})
            risk = comprehensive_assessment.get("risk_level")
            if risk in {"high", "critical"}:
                suggestions.append({"source": "risk_assessment", "description": "ä¼˜å…ˆä¿®å¤é«˜é£é™©åŠæ½œåœ¨å®‰å…¨æ¼æ´ã€‚", "priority": "high"})
            if not suggestions:
                suggestions.append({"source": "general", "description": "æ•´ä½“è´¨é‡è‰¯å¥½ï¼Œæ— éœ€ç«‹å³åŠ¨ä½œã€‚", "priority": "low"})
            return suggestions
        except Exception as e:
            return [{"error": f"æ•´åˆå»ºè®®ç”Ÿæˆå¤±è´¥: {e}"}]

    async def _generate_final_quality_report(self, ai_analysis: Dict[str, Any], static_scan_results: Dict[str, Any], comprehensive_assessment: Dict[str, Any], integrated_suggestions: List[Dict[str, Any]]) -> Dict[str, Any]:
        """ç”Ÿæˆæœ€ç»ˆèšåˆæŠ¥å‘Šã€‚"""
        try:
            return {
                "overview": {
                    "risk_level": comprehensive_assessment.get("risk_level"),
                    "estimated_quality_grade": comprehensive_assessment.get("estimated_quality_grade"),
                    "total_static_issues": comprehensive_assessment.get("total_issues"),
                    "ai_quality_prediction": comprehensive_assessment.get("ai_predicted_quality"),
                    "ai_confidence": comprehensive_assessment.get("ai_confidence")
                },
                "integrated_suggestions": integrated_suggestions,
                "key_static_insights": comprehensive_assessment.get("key_static_insights", []),
                "ai_refactoring_plan": ai_analysis.get("refactoring_suggestions"),
                "generated_timestamp": self._get_current_time()
            }
        except Exception as e:
            return {"error": f"æœ€ç»ˆæŠ¥å‘Šç”Ÿæˆå¤±è´¥: {e}"}

    def _split_code_into_chunks(self, code_content: str, max_length: int = 256) -> List[str]:
        """Split code into smaller chunks to fit CPU memory constraints"""
        # è¿™é‡Œçš„max_lengthæ˜¯æˆ‘ä»¬è‡ªå·±æ§åˆ¶çš„ä»£ç å—å¤§å°,è€Œä¸æ˜¯transformeræ¨¡å‹çš„å‚æ•°
        # æ‰€ä»¥ä¸éœ€è¦æ‹…å¿ƒè­¦å‘Š
        chunk_size = max_length  # ä¸ºæ¸…æ™°èµ·è§é‡å‘½åå˜é‡
        
        if len(code_content) <= chunk_size:
            return [code_content]
        
        chunks = []
        lines = code_content.split('\n')
        current_chunk = ""
        
        for line in lines:
            # å¦‚æœå•è¡Œå°±è¶…è¿‡æœ€å¤§é•¿åº¦,ç›´æ¥æˆªæ–­
            if len(line) > chunk_size:
                if current_chunk:
                    chunks.append(current_chunk.strip())
                    current_chunk = ""
                chunks.append(line[:chunk_size])
                continue
            
            # æ£€æŸ¥æ·»åŠ è¿™ä¸€è¡Œæ˜¯å¦ä¼šè¶…è¿‡é™åˆ¶
            if len(current_chunk) + len(line) + 1 <= chunk_size:
                current_chunk += line + "\n"
            else:
                if current_chunk:
                    chunks.append(current_chunk.strip())
                current_chunk = line + "\n"
        
        # æ·»åŠ æœ€åä¸€ä¸ªå—
        if current_chunk:
            chunks.append(current_chunk.strip())
        
        # é™åˆ¶æœ€å¤§å—æ•°é‡ä»¥èŠ‚çœå†…å­˜
        return chunks[:10]

    def _parse_ai_analysis(self, generated_text: str) -> Dict[str, Any]:
        """Parse AI-generated analysis text into structured data"""
        # ç®€å•çš„è§£æé€»è¾‘,å®é™…åº”ç”¨ä¸­å¯ä»¥æ›´å¤æ‚
        lines = generated_text.split('\n')
        
        analysis = {
            "issues_found": [],
            "quality_score": 7.0,  # é»˜è®¤åˆ†æ•°
            "recommendations": []
        }
        
        for line in lines:
            if "é—®é¢˜" in line or "issue" in line.lower():
                analysis["issues_found"].append(line.strip())
            elif "å»ºè®®" in line or "recommend" in line.lower():
                analysis["recommendations"].append(line.strip())
            elif "åˆ†æ•°" in line or "score" in line.lower():
                # å°è¯•æå–åˆ†æ•°
                import re
                score_match = re.search(r'(\d+(?:\.\d+)?)', line)
                if score_match:
                    analysis["quality_score"] = float(score_match.group(1))
        
        return analysis

    def _parse_suggestions(self, suggestions_text: str) -> List[Dict[str, Any]]:
        """Parse suggestion text into structured data"""
        suggestions = []
        lines = suggestions_text.split('\n')
        
        for i, line in enumerate(lines):
            if line.strip() and not line.startswith('#'):
                suggestions.append({
                    "suggestion_id": i + 1,
                    "description": line.strip(),
                    "priority": "medium",
                    "category": "general"
                })
        
        return suggestions[:5]  # é™åˆ¶æ•°é‡

    async def _read_code_files(self, code_directory: str) -> str:
        """Read code files from directory"""
        
        code_content = ""
        supported_extensions = ['.py', '.js', '.java', '.cpp', '.c', '.cs', '.go', '.rs']
        
        try:
            for root, dirs, files in os.walk(code_directory):
                for file in files[:10]:  # é™åˆ¶æ–‡ä»¶æ•°é‡
                    if any(file.endswith(ext) for ext in supported_extensions):
                        file_path = os.path.join(root, file)
                        try:
                            with open(file_path, 'r', encoding='utf-8') as f:
                                content = f.read()
                                code_content += f"\n\n# File: {file}\n{content}\n"
                        except Exception as e:
                            continue
                            
                if len(code_content) > 10000:  # é™åˆ¶æ€»é•¿åº¦
                    break
                    
        except Exception as e:
            log("ai_code_quality_agent", LogLevel.WARNING, f"è¯»å–ä»£ç æ–‡ä»¶æ—¶å‡ºé”™: {e}")
            
        return code_content

    def _fallback_quality_analysis(self, code_content: str) -> Dict[str, Any]:
        """Fallback analysis when AI model is not available"""
        return {
            "fallback_analysis": True,
            "basic_metrics": {
                "lines_of_code": len(code_content.split('\n')),
                "estimated_complexity": "medium",
                "has_comments": "TODO" in code_content or "FIXME" in code_content
            },
            "basic_recommendations": [
                "Recommend using AI model for more detailed analysis",
                "Check code comments and documentation",
                "Consider adding unit tests"
            ]
        }

    def _fallback_improvement_suggestions(self, code_content: str) -> List[Dict[str, Any]]:
        """Fallback improvement suggestions"""
        return [
            {
                "suggestion_id": 1,
                "description": "Recommend using AI model for more accurate analysis",
                "priority": "high",
                "category": "system"
            }
        ]

    def _fallback_refactoring_suggestions(self, code_content: str) -> Dict[str, Any]:
        """Fallback refactoring suggestions"""
        return {
            "fallback_refactoring": True,
            "basic_suggestions": [
                "Check function length and complexity",
                "Extract duplicate code",
                "Improve naming conventions"
            ]
        }

    async def _execute_task_impl(self, task_data: Dict[str, Any]) -> Dict[str, Any]:
        """Execute AI-driven quality analysis task"""
        return await self._ai_driven_quality_analysis(
            task_data.get("code_content", ""),
            task_data.get("code_directory", "")
        )

    def _get_current_time(self) -> str:
        """Get current timestamp"""
        import datetime
        return datetime.datetime.now().isoformat()
    
    # DEBUG log:
    # Compatibility layer removed (Option A). All interactions must use async message workflow.
    # If external code still calls former sync methods, raise explicit error to guide migration.
    def __getattr__(self, item):
        removed = {
            'load_model', 'analyze_code_quality', 'analyze_file',
            'generate_recommendations', 'calculate_quality_score'
        }
        if item in removed:
            raise AttributeError(
                f"'{item}' has been removed. Use async message-based requests: send 'quality_analysis_request' and listen for 'analysis_result'."
            )
        raise AttributeError(item)