import os
import re
import json
import datetime
import torch
import asyncio
from typing import Dict, Any, Optional, List, Tuple
from pathlib import Path

from transformers import AutoModelForCausalLM
from .base_agent import BaseAgent, Message
from infrastructure.config.ai_agents import get_ai_agent_config
from infrastructure.database.sqlite.service import DatabaseService
from infrastructure.database.weaviate.service import WeaviateVectorService
from infrastructure.database.vector_sync import (
    IssuePatternSyncService,
    DefaultKnowledgeEncodingAgent,
)
from utils import log, LogLevel

class AIDrivenDatabaseManageAgent(BaseAgent):
    """AIé©±åŠ¨æ•°æ®åº“ç®¡ç†æ™ºèƒ½ä½“ - è´Ÿè´£è§£æç”¨æˆ·éœ€æ±‚å¹¶è½¬æ¢ä¸ºæ•°æ®åº“æ“ä½œ
    
    æ ¸å¿ƒåŠŸèƒ½:
    1. ç”¨æˆ·éœ€æ±‚è§£æ - ä½¿ç”¨AIæ¨¡å‹ç†è§£ç”¨æˆ·æ„å›¾
    2. æ•°æ®åº“æ“ä½œè½¬æ¢ - å°†è‡ªç„¶è¯­è¨€éœ€æ±‚è½¬æ¢ä¸ºå…·ä½“æ•°æ®åº“æ“ä½œ
    3. çŸ¥è¯†æ£€ç´¢ - ä¸ºåç»­åˆ†ææ¨¡å‹æä¾›æ•°æ®åº“çŸ¥è¯†æŸ¥è¯¢
    4. ä¸ç”¨æˆ·æ²Ÿé€šä»£ç†æ¨¡å‹ä¿æŒä¸€è‡´
    """
    
    def __init__(self):
        super().__init__("db_manage_agent", "AI Database Management Agent")
        
        # AIæ¨¡å‹ç»„ä»¶ - ä¸ç”¨æˆ·æ²Ÿé€šä»£ç†ä¿æŒä¸€è‡´
        self.conversation_model = None
        self.tokenizer = None
        self.used_device = "gpu"
        self.used_device_map = None
        
        # ä»ç»Ÿä¸€é…ç½®è·å–
        self.agent_config = get_ai_agent_config().get_user_communication_agent_config()
        
        # æ¨¡å‹é…ç½®
        self.model_name = self.agent_config.get("model_name", "Qwen/Qwen1.5-7B-Chat")
        
        # ç¡¬ä»¶è¦æ±‚ï¼šä»é…ç½®è¯»å–
        self.max_memory_mb = self.agent_config.get("max_memory_mb", 14336)
        
        # AIæ¨¡å‹çŠ¶æ€
        self.ai_enabled = False
        
        # æ•°æ®åº“æ“ä½œè®°å½•
        self.database_operations = {}
        
        # ä¼šè¯ç®¡ç†
        self.session_memory = {}

        # æ•°æ®å±‚ç»„ä»¶
        self.db_service = DatabaseService()
        self.vector_service = WeaviateVectorService(embed_fn=self._default_embed)
        self.encoding_agent = DefaultKnowledgeEncodingAgent(embed_fn=self._default_embed)
        self.sync_service = IssuePatternSyncService(
            db_service=self.db_service,
            vector_service=self.vector_service,
            agent=self.encoding_agent,
        )
    
    async def initialize_data_manage(self, agent_integration=None):
        """åˆå§‹åŒ–AIæ¨¡å‹å’Œä»£ç†é›†æˆ"""
        try:
            self.agent_integration = agent_integration
            await self._initialize_ai_models()
            return True
        except Exception as e:
            log("db_manage_agent", LogLevel.ERROR, f"AIæ•°æ®åº“ç®¡ç†ä»£ç†åˆå§‹åŒ–é”™è¯¯: {e}")
            return False
    
    async def _initialize_ai_models(self):
        """åˆå§‹åŒ–Qwen1.5-7Bæ¨¡å‹ - ä¸ç”¨æˆ·æ²Ÿé€šä»£ç†ä¿æŒä¸€è‡´"""
        try:
            from transformers import pipeline, AutoTokenizer

            log("db_manage_agent", LogLevel.INFO, "ğŸ”§ å¼€å§‹åˆå§‹åŒ–æ•°æ®åº“ç®¡ç†æ¨¡å‹...")
            log("db_manage_agent", LogLevel.INFO, f"ğŸ“¦ æ­£åœ¨åŠ è½½æ¨¡å‹: {self.model_name}")

            cache_dir = get_ai_agent_config().get_model_cache_dir()
            # ç¡®ä¿ç¼“å­˜ç›®å½•æ˜¯ç»å¯¹è·¯å¾„
            if not os.path.isabs(cache_dir):
                cache_dir = os.path.abspath(cache_dir)
            log("db_manage_agent", LogLevel.INFO, f"ğŸ’¾ ç¼“å­˜ç›®å½•: {cache_dir}")

            # ç¡®ä¿ç¼“å­˜ç›®å½•å­˜åœ¨
            os.makedirs(cache_dir, exist_ok=True)

            local_files_only = False
            # æ£€æŸ¥æ¨¡å‹æ–‡ä»¶æ˜¯å¦å·²å­˜åœ¨
            model_path = os.path.join(cache_dir, f"models--{self.model_name.replace('/', '--')}")
            # æ£€æŸ¥å¿«ç…§ç›®å½•æ˜¯å¦å­˜åœ¨ä¸”ä¸ä¸ºç©º
            snapshots_path = os.path.join(model_path, "snapshots")
            model_files_exist = (
                os.path.exists(model_path) and 
                os.path.exists(snapshots_path) and 
                os.listdir(snapshots_path)
            )

            if model_files_exist:
                local_files_only = True
                log("db_manage_agent", LogLevel.INFO, "ğŸ” æ£€æµ‹åˆ°æœ¬åœ°ç¼“å­˜æ¨¡å‹æ–‡ä»¶ï¼Œå°†ä½¿ç”¨æœ¬åœ°æ–‡ä»¶åŠ è½½")
            else:
                log("db_manage_agent", LogLevel.INFO, "ğŸŒ æœªæ£€æµ‹åˆ°æœ¬åœ°ç¼“å­˜æ¨¡å‹ï¼Œå°†ä»ç½‘ç»œä¸‹è½½")

            # åˆå§‹åŒ–tokenizer
            log("db_manage_agent", LogLevel.INFO, "ğŸ”§ ä½¿ç”¨Qwené…ç½®åŠ è½½tokenizer...")
            if local_files_only and model_files_exist:
                # ä½¿ç”¨æœ¬åœ°è·¯å¾„åŠ è½½tokenizerï¼Œé¿å…ç½‘ç»œè¯·æ±‚
                snapshot_dirs = os.listdir(snapshots_path)
                if snapshot_dirs:
                    model_local_path = os.path.join(snapshots_path, snapshot_dirs[0])
                    self.tokenizer = AutoTokenizer.from_pretrained(
                        model_local_path,
                        cache_dir=cache_dir,
                        trust_remote_code=True,
                        local_files_only=True
                    )
                else:
                    raise Exception("æœªæ‰¾åˆ°æœ‰æ•ˆçš„æ¨¡å‹å¿«ç…§ç›®å½•")
            else:
                # åœ¨çº¿æ¨¡å¼æˆ–æœ¬åœ°æ–‡ä»¶ä¸å®Œæ•´æ—¶ä½¿ç”¨æ¨¡å‹åç§°
                self.tokenizer = AutoTokenizer.from_pretrained(
                    self.model_name, 
                    cache_dir=cache_dir,
                    trust_remote_code=True,
                    local_files_only=local_files_only
                )
            log("db_manage_agent", LogLevel.INFO, "âœ… TokenizeråŠ è½½æˆåŠŸ")

            # é…ç½®tokenizer
            if self.tokenizer.pad_token is None:
                self.tokenizer.pad_token = self.tokenizer.eos_token
                log("db_manage_agent", LogLevel.INFO, "âœ… Tokenizeré…ç½®æˆåŠŸ")

            # è®¾ç½®padding_side
            self.tokenizer.padding_side = "left"
            log("db_manage_agent", LogLevel.INFO, "ğŸ”§ å·²è®¾ç½®padding_side")

            # åˆå§‹åŒ–å¯¹è¯ç”Ÿæˆpipeline
            log("db_manage_agent", LogLevel.INFO, f"ğŸ’» ä½¿ç”¨è®¾å¤‡: {self.used_device}")

            log("db_manage_agent", LogLevel.INFO, "ğŸ”§ åŠ è½½æ¨¡å‹...")
            if local_files_only and model_files_exist:
                snapshot_dirs = os.listdir(snapshots_path)
                if snapshot_dirs:
                    model_local_path = os.path.join(snapshots_path, snapshot_dirs[0])
                    self.model = AutoModelForCausalLM.from_pretrained(
                        model_local_path,
                        cache_dir=cache_dir,
                        trust_remote_code=True,
                        device_map="auto" if self.used_device == "gpu" else None,
                        torch_dtype=torch.float16 if self.used_device == "gpu" else torch.float32,
                        local_files_only=True
                    )
                else:
                    raise Exception("æœªæ‰¾åˆ°æœ‰æ•ˆçš„æ¨¡å‹å¿«ç…§ç›®å½•")
            else:
                self.model = AutoModelForCausalLM.from_pretrained(
                    self.model_name,
                    cache_dir=cache_dir,
                    trust_remote_code=True,
                    device_map="auto" if self.used_device == "gpu" else None,
                    torch_dtype=torch.float16 if self.used_device == "gpu" else torch.float32,
                    local_files_only=local_files_only
                )

            log("db_manage_agent", LogLevel.INFO, "ğŸ”¥ é¢„çƒ­æ•°æ®åº“ç®¡ç†æ¨¡å‹...")
            test_prompt = "ä½ å¥½"
            inputs = self.tokenizer(test_prompt, return_tensors="pt")
            with torch.no_grad():
                outputs = self.model.generate(
                    inputs.input_ids,
                    max_new_tokens=50,
                    do_sample=False,
                    pad_token_id=self.tokenizer.eos_token_id
                )
            
            self.ai_enabled = True
            log("db_manage_agent", LogLevel.INFO, "ğŸ‰ AIæ•°æ®åº“ç®¡ç†æ¨¡å‹åˆå§‹åŒ–å®Œæˆ")

        except ImportError:
            error_msg = "transformersåº“æœªå®‰è£…,AIåŠŸèƒ½æ— æ³•ä½¿ç”¨"
            log("db_manage_agent", LogLevel.ERROR, f"âŒ {error_msg}")
            raise ImportError(error_msg)
        except Exception as e:
            error_msg = f"AIæ¨¡å‹åˆå§‹åŒ–å¤±è´¥: {e}"
            log("db_manage_agent", LogLevel.ERROR, f"âŒ {error_msg}")
            raise Exception(error_msg)

    async def handle_message(self, message: Message):
        """å¤„ç†æ¶ˆæ¯ - å®ç°BaseAgentçš„æŠ½è±¡æ–¹æ³•"""
        try:
            if message.message_type == "user_requirement":
                await self._process_user_requirement(message.content)
            elif message.message_type == "knowledge_request":
                await self._process_knowledge_request(message.content)
            else:
                log("db_manage_agent", LogLevel.ERROR, f"âŒ ç³»ç»Ÿé”™è¯¯: æ”¶åˆ°æœªçŸ¥æ¶ˆæ¯ç±»å‹: {message.message_type}")
        except Exception as e:
            log("db_manage_agent", LogLevel.ERROR, f"âŒ ç³»ç»Ÿé”™è¯¯: æ¶ˆæ¯å¤„ç†å¼‚å¸¸ ({str(e)})")
            raise

    async def _execute_task_impl(self, task_data: Dict[str, Any]) -> Dict[str, Any]:
        """æ‰§è¡Œå…·ä½“ä»»åŠ¡ - å®ç°BaseAgentçš„æŠ½è±¡æ–¹æ³•"""
        # æš‚æ—¶è¿”å›ç©ºç»“æœ
        return {"status": "success", "message": "Task executed successfully"}

    # === å¯¹å¤–æ¥å£æ–¹æ³• ===

    async def user_requirement_interpret(
        self,
        user_requirement: Optional[Dict[str, Any]] = None,
        session_id: str = "default",
    ) -> Dict[str, Any]:
        """
        ç”¨æˆ·éœ€æ±‚è§£ææ¥å£
        - å…¥å‚ user_requirement ä¸­åŒ…å«è‡ªç„¶è¯­è¨€ db_tasks
        - é€šè¿‡ Qwen + ç‰¹å®š Prompt ç¿»è¯‘ä¸ºç»“æ„åŒ– DB æ“ä½œåæ‰§è¡Œ
        """
        log("db_manage_agent", LogLevel.INFO, f"ğŸ“ å¼€å§‹è§£æç”¨æˆ·éœ€æ±‚ï¼Œä¼šè¯ID: {session_id}")

        tasks = self._normalize_db_tasks(user_requirement)
        # ç»Ÿä¸€é€šè¿‡ LLM ç¿»è¯‘è‡ªç„¶è¯­è¨€ db_tasks -> ç»“æ„åŒ–ä»»åŠ¡
        if tasks:
            llm_plan = await self._translate_tasks_with_llm(tasks, session_id=session_id)
            if llm_plan:
                tasks = llm_plan

        if not tasks:
            return {
                "status": "noop",
                "session_id": session_id,
                "results": [],
                "message": "æœªè¯†åˆ«åˆ°å¯æ‰§è¡Œçš„æ•°æ®åº“ä»»åŠ¡",
            }

        results: List[Dict[str, Any]] = []
        for task in tasks:
            try:
                result = await self._handle_single_db_task(task, session_id)
                results.append({"task": task, "status": "success", "result": result})
            except Exception as e:
                log("db_manage_agent", LogLevel.ERROR, f"âŒ å¤„ç†æ•°æ®åº“ä»»åŠ¡å¤±è´¥: {e}")
                results.append({"task": task, "status": "failed", "error": str(e)})

        overall_status = (
            "success"
            if all(item["status"] == "success" for item in results)
            else "partial"
        )

        return {
            "status": overall_status,
            "session_id": session_id,
            "results": results,
            "message": "æ•°æ®åº“ä»»åŠ¡æ‰§è¡Œå®Œæˆ",
        }

    async def get_knowledge_from_database(self, scan_results: Dict[str, Any]) -> Dict[str, Any]:
        """
        çŸ¥è¯†æ£€ç´¢æ¥å£ - æä¾›ç»™åç»­å¾…å¼€å‘çš„äºŒæ¬¡åˆ†ææ¨¡å‹
        
        å‚æ•°:
            scan_results: JSONæ ¼å¼çš„ä»£ç æ‰«æç»“æœ
            
        è¿”å›:
            ä»æ•°æ®åº“æ£€ç´¢åˆ°çš„ç›¸å…³çŸ¥è¯†
        """
        log("db_manage_agent", LogLevel.INFO, "ğŸ” å¼€å§‹æ£€ç´¢æ•°æ®åº“çŸ¥è¯†")
        
        # æš‚æ—¶è¿”å›é»˜è®¤å€¼
        return {
            "status": "success",
            "knowledge_data": {},
            "message": "çŸ¥è¯†æ£€ç´¢åŠŸèƒ½å¾…å®ç°"
        }

    # === å†…éƒ¨å¤„ç†æ–¹æ³• ===

    async def _process_user_requirement(self, content: Dict[str, Any]):
        """å¤„ç†ç”¨æˆ·éœ€æ±‚æ¶ˆæ¯"""
        user_requirement = content.get("requirement", {})
        session_id = content.get("session_id", "default")
        
        # è°ƒç”¨ç”¨æˆ·éœ€æ±‚è§£ææ¥å£
        result = await self.user_requirement_interpret(user_requirement, session_id)
        
        # è®°å½•æ“ä½œç»“æœ
        if session_id not in self.database_operations:
            self.database_operations[session_id] = []
        
        self.database_operations[session_id].append({
            "timestamp": self._get_current_time(),
            "operation": "user_requirement_interpret",
            "result": result
        })

    async def _process_knowledge_request(self, content: Dict[str, Any]):
        """å¤„ç†çŸ¥è¯†è¯·æ±‚æ¶ˆæ¯"""
        scan_results = content.get("scan_results", {})
        
        # è°ƒç”¨çŸ¥è¯†æ£€ç´¢æ¥å£
        result = await self.get_knowledge_from_database(scan_results)
        
        # è®°å½•æ“ä½œç»“æœ
        if "knowledge_requests" not in self.database_operations:
            self.database_operations["knowledge_requests"] = []
        
        self.database_operations["knowledge_requests"].append({
            "timestamp": self._get_current_time(),
            "operation": "get_knowledge_from_database",
            "result": result
        })

    def _get_current_time(self) -> str:
        """è·å–å½“å‰æ—¶é—´å­—ç¬¦ä¸²"""
        return datetime.datetime.now().isoformat()

    # ================== å†…éƒ¨è¾…åŠ©æ–¹æ³• ================== #
    def _normalize_db_tasks(
        self,
        user_requirement: Optional[Dict[str, Any]],
    ) -> List[Dict[str, Any]]:
        """
        ä»…ä» user_requirement æå–è‡ªç„¶è¯­è¨€ db_tasksã€‚
        """
        if isinstance(user_requirement, dict):
            tasks = user_requirement.get("db_tasks") or []
            if isinstance(tasks, list):
                return [t for t in tasks if isinstance(t, dict)]
        return []

    async def _translate_tasks_with_llm(
        self, raw_tasks: List[Dict[str, Any]], session_id: str
    ) -> List[Dict[str, Any]]:
        """
        ä½¿ç”¨ Qwen å°†è‡ªç„¶è¯­è¨€ db_tasks ç¿»è¯‘ä¸ºç»“æ„åŒ– DB æ“ä½œã€‚
        è¾“å…¥ç¤ºä¾‹ï¼ˆprompts.py 106-112ï¼‰ï¼š
        {
          "db_tasks": [
            {"project": "...", "description": "æ•°æ®åº“æ“ä½œçš„è‡ªç„¶è¯­è¨€æè¿°"}
          ]
        }

        æœŸæœ›è¾“å‡º JSON æ•°ç»„å…ƒç´ ï¼š
        {
          "target": "issue_pattern|curated_issue|review_session",
          "action": "create|update|delete|sync",
          "data": { ... ä¸ models.py å­—æ®µå¯¹é½ ... }
        }
        """
        if not self.ai_enabled or not self.tokenizer or not hasattr(self, "model"):
            log("db_manage_agent", LogLevel.WARNING, "âš ï¸ AI æœªå¯ç”¨ï¼Œè·³è¿‡ LLM ç¿»è¯‘")
            return []

        # ä½¿ç”¨ç‹¬ç«‹ Prompt æŒ‡ä»¤åŒ–ç¿»è¯‘è¡Œä¸º
        try:
            from infrastructure.config.prompts import get_prompt
            system_prompt = get_prompt(
                "db_task_translation",
                model_name=self.model_name,
            )
        except Exception:
            system_prompt = (
                "ä½ æ˜¯æ•°æ®åº“ç®¡ç†ä»£ç†ã€‚æ ¹æ® db_tasks çš„ project å’Œ descriptionï¼Œ"
                "å°†éœ€æ±‚ç¿»è¯‘ä¸º SQLite çš„ç»“æ„åŒ–æ“ä½œï¼Œå­—æ®µå¯¹é½ review_sessions/curated_issues/issue_patternsã€‚"
                "è¾“å‡º JSON æ•°ç»„ï¼Œä»…åŒ…å« target, action, dataï¼Œç¦æ­¢é™„åŠ è¯´æ˜ã€‚"
            )

        try:
            user_content = json.dumps({"db_tasks": raw_tasks}, ensure_ascii=False)
        except Exception:
            user_content = str(raw_tasks)

        prompt = f"{system_prompt}\nç”¨æˆ·è¾“å…¥ï¼š{user_content}\nè¾“å‡º JSONï¼š"
        inputs = self.tokenizer(prompt, return_tensors="pt")
        if self.used_device == "gpu":
            inputs = {k: v.to("cuda") for k, v in inputs.items()}

        with torch.no_grad():
            outputs = self.model.generate(
                inputs["input_ids"],
                max_new_tokens=512,
                do_sample=False,
                pad_token_id=self.tokenizer.eos_token_id,
            )
        generated = self.tokenizer.decode(outputs[0], skip_special_tokens=True)
        parsed = self._extract_structured_tasks_from_text(generated)
        if parsed:
            log("db_manage_agent", LogLevel.INFO, f"âœ… LLM ç¿»è¯‘å¾—åˆ° {len(parsed)} æ¡ä»»åŠ¡")
        else:
            log("db_manage_agent", LogLevel.WARNING, "âš ï¸ æœªèƒ½è§£æ LLM è¾“å‡ºï¼Œè¿”å›ç©ºä»»åŠ¡")
        return parsed

    def _extract_structured_tasks_from_text(self, text: str) -> List[Dict[str, Any]]:
        """
        ä»æ¨¡å‹è¾“å‡ºä¸­æå– JSON æ•°ç»„ï¼›å®¹é”™ï¼šæˆªå–é¦–å°¾çš„ JSON ç‰‡æ®µã€‚
        """
        try:
            data = json.loads(text)
            return data if isinstance(data, list) else []
        except Exception:
            pass
        try:
            start = text.find("[")
            end = text.rfind("]")
            if start != -1 and end != -1 and end > start:
                snippet = text[start : end + 1]
                data = json.loads(snippet)
                return data if isinstance(data, list) else []
        except Exception:
            return []

    async def _handle_single_db_task(
        self, task: Dict[str, Any], session_id: str
    ) -> Dict[str, Any]:
        """
        æ‰§è¡Œå•æ¡æ•°æ®åº“ä»»åŠ¡ã€‚
        é¢„æœŸå­—æ®µï¼š
            - action: create/update/delete/sync
            - target/table: review_session/curated_issue/issue_pattern
            - data: å…·ä½“å­—æ®µ
        """
        action = str(
            task.get("action") or task.get("op") or task.get("type") or ""
        ).lower()
        target = str(
            task.get("target") or task.get("table") or task.get("object") or ""
        ).lower()
        data = task.get("data") if isinstance(task.get("data"), dict) else {}

        # å¦‚æœç¼ºå°‘ action/targetï¼Œå°è¯•æ ¹æ®å­—æ®µæ¨æ–­ï¼ˆå¸¸è§åœºæ™¯ï¼šæ–°å¢ IssuePatternï¼‰
        if not action and task:
            if "error_type" in task:
                action = "create"
                target = target or "issue_pattern"
                data = {**task}
        if not target and "table" in task:
            target = str(task["table"]).lower()

        if target in ("issue_pattern", "issuepattern", "pattern"):
            return await self._handle_issue_pattern_task(action, data)
        if target in ("curated_issue", "issue", "curated"):
            return await self._handle_curated_issue_task(action, data)
        if target in ("review_session", "session"):
            return await self._handle_review_session_task(action, data, session_id)

        raise ValueError(f"æœªçŸ¥çš„æ•°æ®åº“ä»»åŠ¡ç›®æ ‡: {target or 'æœªæä¾›'}")

    async def _handle_issue_pattern_task(
        self, action: str, data: Dict[str, Any]
    ) -> Dict[str, Any]:
        """
        å¤„ç† IssuePattern ç›¸å…³ä»»åŠ¡ï¼š
        - create / update / delete / sync
        """
        action = action or "create"
        action = action.lower()

        if action in ("create", "add", "insert", "upsert"):
            payload = self._fill_issue_pattern_defaults(data)
            pattern_id = await self.db_service.create_issue_pattern(**payload)
            layers = data.get("layers") if isinstance(data.get("layers"), list) else ["full"]
            sync_info = await self._sync_issue_pattern_if_possible(pattern_id, layers)
            return {"pattern_id": pattern_id, "weaviate_sync": sync_info}

        if action in ("update", "modify", "upsert"):
            pattern_id = data.get("id") or data.get("pattern_id")
            if not pattern_id:
                raise ValueError("æ›´æ–° IssuePattern éœ€è¦æä¾› id")
            updated = await self.db_service.update_issue_pattern(
                pattern_id=pattern_id,
                error_type=data.get("error_type"),
                error_description=data.get("error_description"),
                problematic_pattern=data.get("problematic_pattern"),
                file_pattern=data.get("file_pattern"),
                class_pattern=data.get("class_pattern"),
                solution=data.get("solution"),
                severity=data.get("severity"),
                status=data.get("status"),
            )
            layers = data.get("layers") if isinstance(data.get("layers"), list) else ["full"]
            sync_info = await self._sync_issue_pattern_if_possible(pattern_id, layers)
            return {"pattern_id": pattern_id, "updated": updated, "weaviate_sync": sync_info}

        if action in ("delete", "remove"):
            pattern_id = data.get("id") or data.get("pattern_id")
            if not pattern_id:
                raise ValueError("åˆ é™¤ IssuePattern éœ€è¦æä¾› id")
            deleted = await self.db_service.delete_issue_pattern(pattern_id)
            weaviate_deleted = self._delete_weaviate_items(pattern_id)
            return {"pattern_id": pattern_id, "deleted": deleted, "weaviate_deleted": weaviate_deleted}

        if action == "sync":
            pattern_id = data.get("id") or data.get("pattern_id")
            if not pattern_id:
                raise ValueError("åŒæ­¥ IssuePattern éœ€è¦æä¾› id")
            layers = data.get("layers") if isinstance(data.get("layers"), list) else ["full"]
            sync_info = await self._sync_issue_pattern_if_possible(pattern_id, layers)
            return {"pattern_id": pattern_id, "weaviate_sync": sync_info}

        raise ValueError(f"ä¸æ”¯æŒçš„ IssuePattern æ“ä½œ: {action}")

    async def _handle_curated_issue_task(
        self, action: str, data: Dict[str, Any]
    ) -> Dict[str, Any]:
        action = action.lower()
        if action in ("create", "add", "insert"):
            required_fields = ["session_id", "file_path", "start_line", "end_line", "code_snippet", "problem_phenomenon", "root_cause", "solution"]
            missing = [f for f in required_fields if f not in data]
            if missing:
                raise ValueError(f"åˆ›å»º CuratedIssue ç¼ºå°‘å¿…å¡«å­—æ®µ: {missing}")
            issue_id = await self.db_service.create_curated_issue(
                session_id=data["session_id"],
                file_path=data["file_path"],
                start_line=data["start_line"],
                end_line=data["end_line"],
                code_snippet=data["code_snippet"],
                problem_phenomenon=data["problem_phenomenon"],
                root_cause=data["root_cause"],
                solution=data["solution"],
                severity=data.get("severity", "medium"),
                status=data.get("status", "open"),
                project_path=data.get("project_path"),
                pattern_id=data.get("pattern_id"),
            )
            return {"issue_id": issue_id}

        if action in ("update", "modify"):
            issue_id = data.get("id") or data.get("issue_id")
            if not issue_id:
                raise ValueError("æ›´æ–° CuratedIssue éœ€è¦æä¾› id")
            updated = await self.db_service.update_curated_issue_status(
                issue_id=issue_id,
                status=data.get("status", "open"),
            )
            return {"issue_id": issue_id, "updated": updated}

        if action in ("delete", "remove"):
            issue_id = data.get("id") or data.get("issue_id")
            if not issue_id:
                raise ValueError("åˆ é™¤ CuratedIssue éœ€è¦æä¾› id")
            deleted = await self.db_service.delete_curated_issue(issue_id)
            return {"issue_id": issue_id, "deleted": deleted}

        raise ValueError(f"ä¸æ”¯æŒçš„ CuratedIssue æ“ä½œ: {action}")

    async def _handle_review_session_task(
        self, action: str, data: Dict[str, Any], session_id: str
    ) -> Dict[str, Any]:
        action = action.lower()
        if action in ("create", "add", "insert"):
            session_db_id = await self.db_service.create_review_session(
                session_id=data.get("session_id", session_id),
                user_message=data.get("user_message", ""),
                code_directory=data.get("code_directory", ""),
                code_patch=data.get("code_patch"),
                git_commit=data.get("git_commit"),
                status=data.get("status", "open"),
            )
            return {"session_db_id": session_db_id}

        if action in ("update", "modify"):
            db_id = data.get("id") or data.get("session_db_id")
            if not db_id:
                raise ValueError("æ›´æ–° ReviewSession éœ€è¦æä¾› id")
            updated = await self.db_service.update_review_session_status(
                db_id=db_id, status=data.get("status", "open")
            )
            return {"session_db_id": db_id, "updated": updated}

        if action in ("delete", "remove"):
            db_id = data.get("id") or data.get("session_db_id")
            if not db_id:
                raise ValueError("åˆ é™¤ ReviewSession éœ€è¦æä¾› id")
            deleted = await self.db_service.delete_review_session(db_id)
            return {"session_db_id": db_id, "deleted": deleted}

        raise ValueError(f"ä¸æ”¯æŒçš„ ReviewSession æ“ä½œ: {action}")

    async def _sync_issue_pattern_if_possible(
        self, pattern_id: int, layers: List[str]
    ) -> Dict[str, Any]:
        if not self.vector_service.client:
            log(
                "db_manage_agent",
                LogLevel.WARNING,
                "âš ï¸ æœªé…ç½® Weaviate clientï¼Œè·³è¿‡å‘é‡åŒæ­¥",
            )
            return {"skipped": True, "reason": "weaviate_client_not_configured"}
        return await self.sync_service.sync_issue_pattern(pattern_id, layers)

    def _delete_weaviate_items(self, pattern_id: int) -> int:
        if not self.vector_service.client:
            return 0
        return self.vector_service.delete_knowledge_items_by_sqlite_id(pattern_id)

    def _fill_issue_pattern_defaults(self, data: Dict[str, Any]) -> Dict[str, Any]:
        required = ["error_type", "error_description", "problematic_pattern", "solution"]
        missing = [f for f in required if not data.get(f)]
        if missing:
            raise ValueError(f"åˆ›å»º IssuePattern ç¼ºå°‘å¿…å¡«å­—æ®µ: {missing}")

        return {
            "error_type": data["error_type"],
            "error_description": data.get("error_description", ""),
            "problematic_pattern": data.get("problematic_pattern", ""),
            "solution": data.get("solution", ""),
            "severity": data.get("severity", "medium"),
            "title": data.get("title"),
            "language": data.get("language"),
            "framework": data.get("framework"),
            "file_pattern": data.get("file_pattern", ""),
            "class_pattern": data.get("class_pattern", ""),
            "tags": data.get("tags"),
            "status": data.get("status", "active"),
        }

    def _default_embed(self, text: str) -> List[float]:
        """
        è½»é‡çº§åµŒå…¥å‡½æ•°ï¼Œç”¨äºåœ¨ç¼ºå°‘çœŸå®æ¨¡å‹æ—¶æä¾›ç¨³å®šå‘é‡ã€‚
        """
        if text is None:
            text = ""
        total = float(sum(ord(c) for c in text))
        length = float(len(text) or 1)
        return [
            length,
            (total % 991) / 991.0,
            (total % 313) / 313.0,
        ]