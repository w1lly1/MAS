import pandas as pd
from datetime import datetime
from typing import Dict, Any
from .base_agent import BaseAgent, Message
from infrastructure.database.sqlite.service import DatabaseService
from infrastructure.reports import report_manager
import os

class SummaryAgent(BaseAgent):
    def __init__(self):
        super().__init__("summary_agent", "ç»“æœæ±‡æ€»è¾“å‡ºæ™ºèƒ½ä½“")
        self.db_service = DatabaseService()
        self.analysis_results = {}
        self.run_meta = {}  # run_id -> {'expected': set(ids), 'completed': set(ids), 'issues': [], 'target_directory': str, 'closed': bool}
        self._last_progress_print = {}  # run_id -> completed_count å·²æ‰“å°çŠ¶æ€ï¼Œé˜²æ­¢åˆ·å±

    async def handle_message(self, message: Message):
        if message.message_type == 'run_init':
            run_id = message.content.get('run_id')
            req_ids = set(message.content.get('requirement_ids', []))
            if run_id:
                meta = self.run_meta.get(run_id)
                if meta:
                    prev_expected = len(meta['expected'])
                    meta['expected'].update(req_ids)
                    meta['target_directory'] = message.content.get('target_directory') or meta.get('target_directory')
                    print(f"[SummaryAgent] run_init received (merge) run_id={run_id} expected {prev_expected}->{len(meta['expected'])}")
                else:
                    self.run_meta[run_id] = {'expected': req_ids, 'completed': set(), 'issues': [], 'target_directory': message.content.get('target_directory'), 'closed': False}
                    print(f"[SummaryAgent] run_init received run_id={run_id} expected={len(req_ids)}")
            return
        # å¤„ç†åˆ†æç»“æœ
        if message.message_type == "analysis_result":
            run_id = message.content.get('run_id') or message.content.get('analysis_run_id')
            requirement_id = message.content.get("requirement_id")
            analysis_type = message.content.get("analysis_type") or message.content.get("agent_type")
            result = message.content.get("result") or message.content.get("results")
            file_path = message.content.get("file_path")
            readable_file = message.content.get("readable_file")
            if requirement_id not in self.analysis_results:
                self.analysis_results[requirement_id] = {"files": set(), "types": set(), "data": {}, "file_path": file_path, "run_id": run_id, "initial_generated": False, "last_report_types_count": 0}
            record = self.analysis_results[requirement_id]
            if run_id:
                record['run_id'] = run_id
            if file_path:
                record["file_path"] = file_path
            if readable_file:
                record['readable_file'] = readable_file
            record["types"].add(analysis_type)
            record["data"][analysis_type] = result
            record["files"].add(file_path)

            # å›é€€: å¦‚æœ run_init å°šæœªåˆ°è¾¾, åˆ›å»ºå ä½ meta ä»¥å…åç»­æ­¥éª¤ä¸¢å¤±
            if run_id and run_id not in self.run_meta:
                self.run_meta[run_id] = {'expected': set(), 'completed': set(), 'issues': [], 'target_directory': None, 'closed': False}
                print(f"[SummaryAgent] âš ï¸ run_meta missing; created placeholder for run_id={run_id} (run_init delayed?)")

            await self._try_generate_consolidated_report(requirement_id)
            if run_id:
                self._log_progress(run_id)

    async def _try_generate_consolidated_report(self, requirement_id: int):
        record = self.analysis_results.get(requirement_id)
        if not record:
            return
        collected = record["types"]
        run_id = record.get('run_id')
        if not run_id:
            for res in record['data'].values():
                if isinstance(res, dict):
                    candidate = res.get('run_id') or res.get('analysis_run_id')
                    if candidate:
                        run_id = candidate
                        record['run_id'] = run_id
                        break
        # è§„åˆ™: ä»åœ¨ static_analysis åˆ°è¾¾æ—¶ç”Ÿæˆ/æ›´æ–° consolidated (ä¾¿äºæŸ¥çœ‹é™æ€é˜¶æ®µç»“æœ);
        # ä½†ä»…å½“ ai_analysis ä¹Ÿå·²åŠ å…¥åæ‰æŠŠ requirement è®¡å…¥ completed ä»¥å»¶è¿Ÿ run_summaryã€‚ 
        if 'static_analysis' in collected:
            regenerate = False
            if not record.get('initial_generated'):
                regenerate = True
            elif len(collected) > record.get('last_report_types_count', 0):
                regenerate = True
            if regenerate:
                await self._generate_consolidated_report(requirement_id, record)
                record['initial_generated'] = True
                record['last_report_types_count'] = len(collected)
                # å»¶è¿Ÿå®Œæˆæ¡ä»¶: éœ€è¦åŒ…å« ai_analysis
                if run_id and run_id in self.run_meta and 'ai_analysis' in collected and requirement_id not in self.run_meta[run_id]['completed']:
                    static_data = record['data']
                    issues_local = []
                    static_res = static_data.get("static_analysis", {})
                    for q in static_res.get("quality_issues", [])[:50]:
                        issues_local.append({'source': 'quality', 'severity': q.get('severity','low')})
                    for s in static_res.get("security_issues", [])[:50]:
                        issues_local.append({'source': 'security', 'severity': s.get('severity','low')})
                    for t in static_res.get("type_issues", [])[:50]:
                        issues_local.append({'source': 'type', 'severity': t.get('severity','low')})
                    for st in static_res.get("style_issues", [])[:30]:
                        issues_local.append({'source': 'style', 'severity': st.get('severity','low')})
                    self.run_meta[run_id]['issues'].extend(issues_local)
                    self.run_meta[run_id]['completed'].add(requirement_id)
                    await self._maybe_finalize_run(run_id)
        # ä¸åˆ é™¤ recordï¼Œå…è®¸åç»­ç±»å‹è¡¥é½

    async def _generate_consolidated_report(self, requirement_id: int, record):
        data = record["data"]
        file_path = record.get("file_path")
        run_id = record.get('run_id')
        # æ–°å¢: ç”Ÿæˆå¯è¯»æ–‡ä»¶ç›¸å¯¹è·¯å¾„åç§°
        rel_path = None
        if run_id and run_id in self.run_meta:
            base = self.run_meta[run_id].get('target_directory')
            if base and file_path:
                try:
                    rel_path = os.path.relpath(file_path, base)
                except Exception:
                    rel_path = file_path
        if not rel_path:
            rel_path = file_path or f"req_{requirement_id}"
        sanitized = self._sanitize_rel_path(rel_path)
        issues = []
        def add_issue(src, description, severity="low", line=None, tool=None):
            issues.append({
                "requirement_id": requirement_id,
                "file": file_path,
                "source": src,
                "severity": severity,
                "line": line,
                "description": description,
                "tool": tool,
                "run_id": run_id
            })
        # static issues
        static_res = data.get("static_analysis", {})
        for q in static_res.get("quality_issues", [])[:50]:
            add_issue("quality", q.get("message"), q.get("severity"), q.get("line"), q.get("tool"))
        for s in static_res.get("security_issues", [])[:50]:
            add_issue("security", s.get("message"), s.get("severity"), s.get("line"), s.get("tool"))
        for t in static_res.get("type_issues", [])[:50]:
            add_issue("type", t.get("message"), t.get("severity"), t.get("line"), t.get("tool"))
        for st in static_res.get("style_issues", [])[:30]:
            add_issue("style", st.get("message"), st.get("severity"), st.get("line"), st.get("tool"))
        # AI è´¨é‡
        ai_res = data.get("ai_analysis", {})
        final_report = ai_res.get("final_report", {})
        for fix in final_report.get("recommendations", {}).get("immediate_fixes", [])[:20]:
            add_issue("ai_quality_fix", fix.get("description"), fix.get("severity", "high"))
        for enh in final_report.get("recommendations", {}).get("quality_enhancements", [])[:20]:
            add_issue("ai_quality_enhancement", enh.get("description"), enh.get("priority", "medium"))
        # å®‰å…¨
        sec_res = data.get("security_analysis", {}).get("ai_security_analysis", {})
        for vuln in sec_res.get("vulnerabilities_detected", [])[:30]:
            add_issue("security_ai", vuln.get("description"), vuln.get("severity"))
        # æ€§èƒ½
        perf_res = data.get("performance_analysis", {}).get("ai_performance_analysis", {})
        for bn in perf_res.get("performance_bottlenecks", [])[:30]:
            add_issue("performance_bottleneck", bn.get("description"), bn.get("severity"))
        # æ±‡æ€»ç»Ÿè®¡
        severity_stats = {}
        for it in issues:
            sev = it.get("severity", "low")
            severity_stats[sev] = severity_stats.get(sev, 0) + 1
        report_payload = {
            "status": "completed",
            "requirement_id": requirement_id,
            "file": file_path,
            "run_id": run_id,
            "issue_count": len(issues),
            "severity_stats": severity_stats,
            "issues": issues,
            "analysis_types": list(record.get("types", [])),
            "readable_file": rel_path,
            "sanitized_name": sanitized,
        }
        ts = datetime.now().strftime('%Y%m%d_%H%M%S')
        filename = f"consolidated_{sanitized}.json"
        if run_id:
            path = report_manager.generate_run_scoped_report(run_id, report_payload, filename, subdir="consolidated")
        else:
            path = report_manager.generate_analysis_report(report_payload, filename=filename)
        print(f"[SummaryAgent] âœ… ç»¼åˆåˆ†æç”Ÿæˆ(FILE={rel_path}) types={report_payload['analysis_types']} issues={len(issues)} high={severity_stats.get('critical',0)+severity_stats.get('high',0)} -> {path}")
        
        # è½¬å‘ç»™å¯è¯»æ€§å¢å¼ºä»£ç†è¿›è¡Œè¿›ä¸€æ­¥å¤„ç†
        await self._forward_to_readability_enhancement(report_payload, requirement_id, run_id, file_path)
        return
    
    async def _forward_to_readability_enhancement(self, report_data: Dict[str, Any], requirement_id: int, run_id: str, file_path: str):
        """å°†æ±‡æ€»æŠ¥å‘Šè½¬å‘ç»™å¯è¯»æ€§å¢å¼ºä»£ç†"""
        try:
            # åˆ›å»ºè½¬å‘æ¶ˆæ¯
            readability_message = Message(
                id=f"{run_id}_{requirement_id}_readability",
                sender=self.agent_id,
                receiver="ai_readability_enhancement_agent",
                content={
                    "requirement_id": requirement_id,
                    "run_id": run_id,
                    "file_path": file_path,
                    "analysis_type": "consolidated_report"
                },
                timestamp=datetime.now().timestamp(),
                message_type="analyze_consolidated_report"
            )
            
            # é€šè¿‡AgentManagerè½¬å‘æ¶ˆæ¯
            from .agent_manager import AgentManager
            await AgentManager.get_instance().route_message(readability_message)
            print(f"[SummaryAgent] ğŸ“¤ å·²è½¬å‘æŠ¥å‘Šç»™å¯è¯»æ€§å¢å¼ºä»£ç† requirement_id={requirement_id} run_id={run_id}")
        except Exception as e:
            print(f"[SummaryAgent] âš ï¸ è½¬å‘åˆ°å¯è¯»æ€§å¢å¼ºä»£ç†å¤±è´¥: {e}")


    async def _maybe_finalize_run(self, run_id: str):
        meta = self.run_meta.get(run_id)
        if not meta or meta.get('closed'):
            return
        if meta['expected'] and meta['expected'] == meta['completed']:
            severity_stats = {}
            for it in meta['issues']:
                sev = it.get('severity','low')
                severity_stats[sev] = severity_stats.get(sev,0)+1
            report_payload = {
                'status': 'run_completed',
                'run_id': run_id,
                'requirements_processed': len(meta['completed']),
                'issue_count': len(meta['issues']),
                'severity_stats': severity_stats,
                'target_directory': meta.get('target_directory')
            }
            ts = datetime.now().strftime('%Y%m%d_%H%M%S')
            filename = f'run_summary.json'
            path = report_manager.generate_run_scoped_report(run_id, report_payload, filename)
            print(f"[SummaryAgent] âœ… è¿è¡Œçº§ç»¼åˆæŠ¥å‘Šç”Ÿæˆ run_id={run_id} total_issues={len(meta['issues'])} -> {path}")
            meta['closed'] = True  # ä¸å†åˆ é™¤ metaï¼Œå…è®¸åç»­AIå¢é‡æ•°æ®å¼•ç”¨ run context

    def _log_progress(self, run_id: str):
        meta = self.run_meta.get(run_id)
        if not meta:
            return
        completed = len(meta['completed'])
        expected_total = len(meta['expected']) if meta['expected'] else 0
        last_printed = self._last_progress_print.get(run_id)
        if last_printed != completed:
            exp_display = expected_total if expected_total else '?'
            print(f"[SummaryAgent] Progress run {run_id}: {completed}/{exp_display} requirements consolidated")
            self._last_progress_print[run_id] = completed

    async def _execute_task_impl(self, task_data: Dict[str, Any]) -> Dict[str, Any]:
        return {"status": "summary_agent_ready"}

    def aggregate_results(self, analysis_results: Dict[str, Any]) -> Dict[str, Any]:
        """Legacy sync aggregation interface used in tests.
        Expects a dict with keys like code_quality/security/performance each containing a score and issue lists.
        Returns unified summary with overall_score, summary_by_category, priority_issues, recommendations."""
        severity_weights = {"critical": 4, "high": 3, "medium": 2, "low": 1, "info": 0}
        summary_by_category = {}
        collected_scores = []
        priority_issues = []
        for category, data in analysis_results.items():
            score = data.get("score")
            if isinstance(score, (int, float)):
                collected_scores.append(score)
            # unify issues field names
            issues = []
            if 'issues' in data and isinstance(data['issues'], list):
                for it in data['issues']:
                    issues.append({
                        "type": it.get("type", category),
                        "severity": it.get("severity", "low"),
                        "count": it.get("count", 1),
                        "category": category
                    })
            if 'vulnerabilities' in data:
                for v in data['vulnerabilities']:
                    issues.append({
                        "type": v.get("type", "vulnerability"),
                        "severity": v.get("severity", "medium"),
                        "count": v.get("count", 1),
                        "category": category
                    })
            if 'bottlenecks' in data:
                for b in data['bottlenecks']:
                    issues.append({
                        "type": b.get("type", "bottleneck"),
                        "severity": b.get("severity", "medium"),
                        "count": b.get("count", 1),
                        "category": category
                    })
            summary_by_category[category] = {
                "score": score,
                "issue_count": sum(i.get("count", 1) for i in issues),
                "issues": issues
            }
            priority_issues.extend(issues)
        overall_score = round(sum(collected_scores)/len(collected_scores), 2) if collected_scores else 0
        priority_issues = self.prioritize_issues(priority_issues)
        recommendations = self._generate_basic_recommendations(summary_by_category)
        return {
            "overall_score": overall_score,
            "summary_by_category": summary_by_category,
            "priority_issues": priority_issues,
            "recommendations": recommendations
        }

    def prioritize_issues(self, issues):
        """Sort issues by severity critical>high>medium>low>info preserving relative order otherwise."""
        severity_order = {"critical": 0, "high": 1, "medium": 2, "low": 3, "info": 4}
        return sorted(issues, key=lambda x: severity_order.get(x.get("severity", "low"), 5))

    def generate_executive_summary(self, aggregated_data: Dict[str, Any]) -> Dict[str, Any]:
        """Produce high-level executive summary from aggregated numeric data."""
        overall = aggregated_data.get('overall_score', 0)
        total_issues = aggregated_data.get('total_issues') or sum(
            v.get('issues', v.get('issue_count', 0)) if isinstance(v, dict) else 0
            for v in (aggregated_data.get('categories') or {}).values()
        )
        critical = aggregated_data.get('critical_issues', 0)
        high = aggregated_data.get('high_issues', 0)
        headline = f"Overall score {overall} with {total_issues} issues (critical:{critical} high:{high})"
        key_metrics = {
            "overall_score": overall,
            "issues_total": total_issues,
            "critical": critical,
            "high": high
        }
        main_concerns = []
        if critical > 0:
            main_concerns.append("å­˜åœ¨å…³é”®é«˜å±é—®é¢˜")
        if overall < 70:
            main_concerns.append("æ•´ä½“è´¨é‡éœ€æå‡")
        success_areas = []
        if overall >= 80:
            success_areas.append("æ€»ä½“è¯„åˆ†è‰¯å¥½")
        return {
            "headline": headline,
            "key_metrics": key_metrics,
            "main_concerns": main_concerns,
            "success_areas": success_areas
        }

    def calculate_trends(self, historical_data):
        """Simple trend analysis comparing first and last entries."""
        if not historical_data:
            return {"score_trend": "stable", "issues_trend": "stable", "improvement_rate": 0}
        start = historical_data[0]
        end = historical_data[-1]
        score_trend = "improving" if end.get('overall_score',0) > start.get('overall_score',0) else ("declining" if end.get('overall_score',0) < start.get('overall_score',0) else "stable")
        issues_trend = "decreasing" if end.get('issues',0) < start.get('issues',0) else ("increasing" if end.get('issues',0) > start.get('issues',0) else "stable")
        improvement_rate = 0
        if start.get('overall_score'):
            improvement_rate = round((end.get('overall_score',0)-start.get('overall_score',0))/start.get('overall_score')*100,2)
        return {"score_trend": score_trend, "issues_trend": issues_trend, "improvement_rate": improvement_rate}

    def analyze_correlations(self, category_data: Dict[str, Any]):
        """Naive correlation insight placeholders between categories based on simple heuristics."""
        correlations = []
        if 'code_quality' in category_data and 'performance' in category_data:
            cq = category_data['code_quality']
            perf = category_data['performance']
            if cq.get('complexity_issues',0) > 0 and perf.get('memory_usage') == 'high':
                correlations.append({
                    "categories": ["code_quality", "performance"],
                    "relationship": "High complexity may contribute to memory usage",
                    "impact": "medium"
                })
        if 'code_quality' in category_data and 'security' in category_data:
            sec = category_data['security']
            if sec.get('vulnerabilities',0) > 0 and category_data['code_quality'].get('maintainability_score', 100) < 80:
                correlations.append({
                    "categories": ["code_quality", "security"],
                    "relationship": "Lower maintainability can hide security issues",
                    "impact": "high"
                })
        return correlations

    def generate_action_plan(self, prioritized_issues):
        """Split prioritized issues into immediate/short/long term buckets."""
        immediate = [i for i in prioritized_issues if i.get('severity') in ('critical','high')][:5]
        short = [i for i in prioritized_issues if i.get('severity') == 'medium'][:5]
        long_term = [i for i in prioritized_issues if i.get('severity') in ('low','info')][:5]
        timeline = {
            "immediate": "0-2 days",
            "short_term": "1-2 weeks",
            "long_term": "1-2 months"
        }
        return {
            "immediate_actions": immediate,
            "short_term_goals": short,
            "long_term_improvements": long_term,
            "timeline": timeline
        }

    def create_comprehensive_report(self, comprehensive_results: Dict[str, Any]) -> Dict[str, Any]:
        project = comprehensive_results.get('project_info', {})
        analysis = comprehensive_results.get('analysis_results', {})
        aggregated = {}
        for k,v in analysis.items():
            aggregated[k] = {
                "score": v.get('score'),
                "issues": v.get('issues') or v.get('vulnerabilities') or v.get('bottlenecks'),
            }
        overall_scores = [v.get('score') for v in analysis.values() if isinstance(v.get('score'), (int,float))]
        overall_score = round(sum(overall_scores)/len(overall_scores),2) if overall_scores else 0
        exec_summary = self.generate_executive_summary({
            'overall_score': overall_score,
            'total_issues': sum((v.get('issues') or v.get('vulnerabilities') or v.get('bottlenecks') or 0) if isinstance(v, dict) else 0 for v in analysis.values()),
            'critical_issues': 0,
            'high_issues': 0,
            'categories': aggregated
        })
        recommendations = ["ä¿®å¤é«˜é£é™©é—®é¢˜", "ä¼˜åŒ–æ€§èƒ½ç“¶é¢ˆ", "æå‡ä»£ç å¯ç»´æŠ¤æ€§"]
        next_steps = ["åˆ¶å®šæ•´æ”¹æ—¶é—´è¡¨", "è·Ÿè¸ªæŒ‡æ ‡å˜åŒ–", "äºŒæ¬¡å®¡æŸ¥"]
        return {
            "project_overview": project,
            "executive_summary": exec_summary,
            "detailed_analysis": analysis,
            "recommendations": recommendations,
            "next_steps": next_steps
        }

    def export_report(self, summary_data: Dict[str, Any], format: str = 'json') -> str:
        import json
        format = format.lower()
        if format == 'json':
            return json.dumps(summary_data, ensure_ascii=False, indent=2)
        if format == 'markdown':
            lines = ["# Summary Report"]
            for k,v in summary_data.items():
                if isinstance(v, (dict,list)):
                    lines.append(f"## {k}")
                    lines.append(f"`{str(v)[:500]}`")
                else:
                    lines.append(f"- **{k}**: {v}")
            return "\n".join(lines)
        if format == 'html':
            import html
            body = ''.join(f"<h2>{k}</h2><pre>{html.escape(str(v)[:1000])}</pre>" for k,v in summary_data.items())
            return f"<html><body><h1>Summary Report</h1>{body}</body></html>"
        return str(summary_data)

    def _generate_basic_recommendations(self, summary_by_category: Dict[str, Any]):
        recs = []
        for cat, val in summary_by_category.items():
            score = val.get('score') or 0
            if score < 75:
                recs.append(f"æ”¹è¿› {cat} ä»¥æå‡å¾—åˆ†")
        if not recs:
            recs.append("ç»´æŒå½“å‰è´¨é‡å¹¶æŒç»­ç›‘æ§")
        return recs

    def _sanitize_rel_path(self, rel_path: str) -> str:
        safe = rel_path.replace(os.sep, '_')
        safe = ''.join(c if c.isalnum() or c in ('_', '.') else '_' for c in safe)
        while '__' in safe:
            safe = safe.replace('__', '_')
        return safe.strip('_') or 'unknown_file'