[
  {
    "test_name": "Config Loading",
    "model_name": "ChatGLM3-6B",
    "status": "pass",
    "duration": 2.318814277648926,
    "message": "Configuration loaded successfully",
    "details": {
      "config_type": "<class 'transformers_modules.THUDM.chatglm3-6b.e9e0406d062cdb887444fe5bd546833920abd4ac.configuration_chatglm.ChatGLMConfig'>",
      "num_layers": 28,
      "hidden_size": 4096,
      "memory_stats": {
        "initial_memory_gb": 4.5232391357421875,
        "peak_memory_gb": 4.5251312255859375,
        "memory_increase_gb": 0.00189208984375,
        "gpu_initial_gb": 0,
        "gpu_peak_gb": 0,
        "gpu_increase_gb": 0
      }
    },
    "error": null,
    "timestamp": "2025-09-15T06:03:27.585416"
  },
  {
    "test_name": "Tokenizer Loading",
    "model_name": "ChatGLM3-6B",
    "status": "pass",
    "duration": 1.6260557174682617,
    "message": "Tokenizer loaded and functioning",
    "details": {
      "tokenizer_type": "<class 'transformers_modules.THUDM.chatglm3-6b.e9e0406d062cdb887444fe5bd546833920abd4ac.tokenization_chatglm.ChatGLMTokenizer'>",
      "vocab_size": 64798,
      "test_text": "你好，我是ChatGLM3助手",
      "decoded_text": "[gMASK] sop 你好，我是ChatGLM3助手",
      "special_tokens": {
        "bos_token": null,
        "eos_token": "</s>",
        "pad_token": "<unk>"
      },
      "memory_stats": {
        "initial_memory_gb": 4.5251312255859375,
        "peak_memory_gb": 4.541049957275391,
        "memory_increase_gb": 0.015918731689453125,
        "gpu_initial_gb": 0,
        "gpu_peak_gb": 0,
        "gpu_increase_gb": 0
      }
    },
    "error": null,
    "timestamp": "2025-09-15T06:03:29.211891"
  },
  {
    "test_name": "Model Loading",
    "model_name": "ChatGLM3-6B",
    "status": "pass",
    "duration": 1933.9143574237823,
    "message": "Model loaded successfully",
    "details": {
      "model_type": "<class 'transformers_modules.THUDM.chatglm3-6b.e9e0406d062cdb887444fe5bd546833920abd4ac.modeling_chatglm.ChatGLMForConditionalGeneration'>",
      "parameter_count": 6243584000,
      "trainable_parameters": 6243584000,
      "device": "cpu",
      "dtype": "torch.float16",
      "memory_stats": {
        "initial_memory_gb": 4.541049957275391,
        "peak_memory_gb": 4.600437164306641,
        "memory_increase_gb": 0.05938720703125,
        "gpu_initial_gb": 0,
        "gpu_peak_gb": 0,
        "gpu_increase_gb": 0
      }
    },
    "error": null,
    "timestamp": "2025-09-15T06:35:43.126853"
  },
  {
    "test_name": "Basic Inference",
    "model_name": "ChatGLM3-6B",
    "status": "fail",
    "duration": 58.7649450302124,
    "message": "Inference test failed: 'ChatGLMForConditionalGeneration' object has no attribute '_extract_past_from_model_output'",
    "details": {
      "memory_stats": {
        "initial_memory_gb": 4.600437164306641,
        "peak_memory_gb": 4.620765686035156,
        "memory_increase_gb": 0.020328521728515625,
        "gpu_initial_gb": 0,
        "gpu_peak_gb": 0,
        "gpu_increase_gb": 0
      }
    },
    "error": "'ChatGLMForConditionalGeneration' object has no attribute '_extract_past_from_model_output'",
    "timestamp": "2025-09-15T06:36:41.892505"
  },
  {
    "test_name": "Batch Processing",
    "model_name": "ChatGLM3-6B",
    "status": "pass",
    "duration": 1.7017762660980225,
    "message": "Batch processing successful",
    "details": {
      "batch_size": 3,
      "input_shape": [
        3,
        6
      ],
      "output_shape": "unknown",
      "memory_stats": {
        "initial_memory_gb": 4.620765686035156,
        "peak_memory_gb": 4.6214141845703125,
        "memory_increase_gb": 0.00064849853515625,
        "gpu_initial_gb": 0,
        "gpu_peak_gb": 0,
        "gpu_increase_gb": 0
      }
    },
    "error": null,
    "timestamp": "2025-09-15T06:36:43.594907"
  },
  {
    "test_name": "Config Loading",
    "model_name": "Qwen2-7B",
    "status": "fail",
    "duration": 0.17430734634399414,
    "message": "Qwen2 config loading failed: Qwen/Qwen2-7B-Chat is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`",
    "details": {
      "memory_stats": {
        "initial_memory_gb": 4.600559234619141,
        "peak_memory_gb": 4.601955413818359,
        "memory_increase_gb": 0.00139617919921875,
        "gpu_initial_gb": 0,
        "gpu_peak_gb": 0,
        "gpu_increase_gb": 0
      }
    },
    "error": "Qwen/Qwen2-7B-Chat is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `hf auth login` or by passing `token=<your_token>`",
    "timestamp": "2025-09-15T06:36:44.483226"
  },
  {
    "test_name": "Config Loading",
    "model_name": "CodeBERT",
    "status": "pass",
    "duration": 0.343184232711792,
    "message": "CodeBERT configuration loaded successfully",
    "details": {
      "config_type": "<class 'transformers.models.roberta.configuration_roberta.RobertaConfig'>",
      "num_hidden_layers": 12,
      "hidden_size": 768,
      "vocab_size": 50265,
      "model_type": "roberta",
      "memory_stats": {
        "initial_memory_gb": 4.601924896240234,
        "peak_memory_gb": 4.601909637451172,
        "memory_increase_gb": -1.52587890625e-05,
        "gpu_initial_gb": 0,
        "gpu_peak_gb": 0,
        "gpu_increase_gb": 0
      }
    },
    "error": null,
    "timestamp": "2025-09-15T06:36:45.054672"
  },
  {
    "test_name": "Tokenizer Loading",
    "model_name": "CodeBERT",
    "status": "pass",
    "duration": 0.7188987731933594,
    "message": "CodeBERT tokenizer loaded and functioning for code",
    "details": {
      "tokenizer_type": "<class 'transformers.models.roberta.tokenization_roberta_fast.RobertaTokenizerFast'>",
      "vocab_size": 50265,
      "tokenization_results": {
        "code_sample_0": {
          "original": "def hello_world():\n    print('Hello, World!')",
          "token_count": 18,
          "decoded_matches": false
        },
        "code_sample_1": {
          "original": "function calculateSum(a, b) { return a + b; }",
          "token_count": 17,
          "decoded_matches": false
        },
        "code_sample_2": {
          "original": "public class HelloWorld { public static void main(String[] args) { System.out.println('Hello'); } }",
          "token_count": 27,
          "decoded_matches": false
        },
        "code_sample_3": {
          "original": "import numpy as np\narray = np.array([1, 2, 3])",
          "token_count": 20,
          "decoded_matches": false
        }
      },
      "special_tokens": {
        "bos_token": "<s>",
        "eos_token": "</s>",
        "sep_token": "</s>",
        "cls_token": "<s>",
        "pad_token": "<pad>",
        "mask_token": "<mask>"
      },
      "memory_stats": {
        "initial_memory_gb": 4.601909637451172,
        "peak_memory_gb": 4.610298156738281,
        "memory_increase_gb": 0.008388519287109375,
        "gpu_initial_gb": 0,
        "gpu_peak_gb": 0,
        "gpu_increase_gb": 0
      }
    },
    "error": null,
    "timestamp": "2025-09-15T06:36:45.773943"
  },
  {
    "test_name": "Model Loading",
    "model_name": "CodeBERT",
    "status": "pass",
    "duration": 7.600191116333008,
    "message": "CodeBERT model loaded successfully",
    "details": {
      "model_type": "<class 'transformers.models.roberta.modeling_roberta.RobertaModel'>",
      "parameter_count": 124645632,
      "parameter_count_millions": 124.6,
      "trainable_parameters": 124645632,
      "device": "cpu",
      "dtype": "torch.float16",
      "has_embeddings": true,
      "has_encoder": true,
      "has_pooler": true,
      "memory_stats": {
        "initial_memory_gb": 4.610298156738281,
        "peak_memory_gb": 5.160907745361328,
        "memory_increase_gb": 0.5506095886230469,
        "gpu_initial_gb": 0,
        "gpu_peak_gb": 0,
        "gpu_increase_gb": 0
      }
    },
    "error": null,
    "timestamp": "2025-09-15T06:36:53.374542"
  },
  {
    "test_name": "Code Embedding",
    "model_name": "CodeBERT",
    "status": "pass",
    "duration": 0.35625147819519043,
    "message": "CodeBERT embedding generation successful",
    "details": {
      "embedding_results": {
        "code_0": {
          "code": "def process_data(data): return data.strip().lower(...",
          "embedding_shape": [
            1,
            768
          ],
          "embedding_norm": 18.703125,
          "input_length": 16
        },
        "code_1": {
          "code": "function processData(data) { return data.trim().to...",
          "embedding_shape": [
            1,
            768
          ],
          "embedding_norm": 19.015625,
          "input_length": 20
        },
        "code_2": {
          "code": "public String processData(String data) { return da...",
          "embedding_shape": [
            1,
            768
          ],
          "embedding_norm": 19.203125,
          "input_length": 22
        }
      },
      "total_codes": 3,
      "memory_stats": {
        "initial_memory_gb": 5.160907745361328,
        "peak_memory_gb": 5.159854888916016,
        "memory_increase_gb": -0.0010528564453125,
        "gpu_initial_gb": 0,
        "gpu_peak_gb": 0,
        "gpu_increase_gb": 0
      }
    },
    "error": null,
    "timestamp": "2025-09-15T06:36:53.731244"
  },
  {
    "test_name": "Code Similarity",
    "model_name": "CodeBERT",
    "status": "pass",
    "duration": 0.1386394500732422,
    "message": "CodeBERT similarity detection working",
    "details": {
      "similarity_results": {
        "pair_0": {
          "code1": "def add_numbers(a, b): return a + b",
          "code2": "function addNumbers(a, b) { return a + b; }",
          "similarity": 0.96728515625,
          "similar": true
        },
        "pair_1": {
          "code1": "for i in range(10): print(i)",
          "code2": "for (int i = 0; i < 10; i++) { System.out.println(i); }",
          "similarity": 0.9521484375,
          "similar": true
        }
      },
      "total_pairs": 2,
      "memory_stats": {
        "initial_memory_gb": 5.159854888916016,
        "peak_memory_gb": 5.159854888916016,
        "memory_increase_gb": 0.0,
        "gpu_initial_gb": 0,
        "gpu_peak_gb": 0,
        "gpu_increase_gb": 0
      }
    },
    "error": null,
    "timestamp": "2025-09-15T06:36:53.870366"
  }
]